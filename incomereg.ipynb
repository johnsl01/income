{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "incomereg.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnsl01/income/blob/master/incomereg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owm9n3f8eQjs",
        "colab_type": "text"
      },
      "source": [
        "#_\n",
        "_Multiple variable (hyperplane) regression_\n",
        "Income data \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8hTCMa9mKAm",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "_ml outline approach_\n",
        "\n",
        "A structured ML student exercise type task typically comprises a set of data with one or more answers per data sample and a second set of data with the answers missing.\n",
        "\n",
        "The basic task is to use machine learning to provide the missing answers.\n",
        "\n",
        "The normal approach is : \n",
        "\n",
        "Explore and understand the data provided - typically producing some basic metrics around the data and preparing some simple correlations between elements of the data and the answers.\n",
        "\n",
        "Assess the quality of the data - normally carried out as part of the exploration this task is more concentrating on the missing and bad data and any extreme outliers - and also looking at any unstructured data (free text strings etc) and determining what remediation is necessary to either impute the missing data - discard samples or manipulate the unstructured data to generate structured elements from it.\n",
        "\n",
        "Carry out some initial ML tasks such as linear (planar) regression and assess the quality of the results on the known answers and provide an initial version of the answers to use as a benchmark for more sophisticated next steps.\n",
        "\n",
        "Make an assesssment based on the information gathered above on the approach to ML - what types of ML tools are approriate to the data and estimate what level of quality could be achieved. For a student / training exercise the requirement may be to consider more than one aproach and to compare the results - or the requirement may be simply to produce the best result, and in this case there may be a submission so the 'real' answers are hidden and only a score available to compare results.\n",
        "\n",
        "Typically the answers provded to ML problems fall in two categories - continuous numerical in which case the problem is generally a regression problem or categorical (ordered or not) in which case the problem is generally a categorisation problem, or one or more of each type. \n",
        "\n",
        "Student exercise can also contain more specific requirements - to use a specific type of ML approach and to demonstrate the impacts of some parameter changes or to examine the impact of under or over fitting to the test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKpZBTxsm4Dk",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "_discription and general notes_\n",
        "\n",
        "y = B0 + B1.X1 + B2.X2 + B3.X3 ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w8maXdCnSNf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIZnfvuMlJqK",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "imports and data loads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fldw8f0uaRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title                 Imports               #\n",
        "###############################################\n",
        "print (\"Imports\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "\n",
        "# need this as we have two categoricals with very large number of \n",
        "# categories (possible with very low variance among them)\n",
        "# one hot - or other multi feature encoding will hugely increase\n",
        "# the dimensionality.\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "\n",
        "# !pip install fancyimpute\n",
        "# import fancyimpute as fi\n",
        "# fancyimpute no longer includes mice - \n",
        "# but the sklearn implementation is experimantal\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from datetime import datetime\n",
        "print (datetime.now())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7oKOzJslmyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title               Data loads              #\n",
        "###############################################\n",
        "print (\"Data loads\")\n",
        "sourcedata = \"https://raw.githubusercontent.com/johnsl01/income/master/incomeknown.csv\"\n",
        "incomeknown_df = pd.read_csv(sourcedata, sep=\",\")\n",
        "\n",
        "sourcedata = \"https://raw.githubusercontent.com/johnsl01/income/master/incomeunknown.csv\"\n",
        "incomeunknown_df = pd.read_csv(sourcedata, sep=\",\")\n",
        "\n",
        "print (datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvy6G37Vs-84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at the data \n",
        "incomeknown_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRwF2doKm8HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and the unknowns:\n",
        "incomeunknown_df.head(10)\n",
        "\n",
        "# looks similar - as to be hoped !"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjaNDmzis37i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dont like the col names - much easier with simple strings with no spaces.\n",
        "incomeknown_df.rename(columns = {\"Year of Record\" : \"Year\",\n",
        "                                 \"Size of City\" : \"CitySize\",\n",
        "                                 \"University Degree\" : \"Degree\",\n",
        "                                 \"Wears Glasses\" : \"Glasses\",\n",
        "                                 \"Hair Color\" : \"Hair\",\n",
        "                                 \"Body Height [cm]\" : \"Height\",\n",
        "                                 \"Income in EUR\" : \"Income\"},\n",
        "                      inplace = True)\n",
        "\n",
        "incomeunknown_df.rename(columns = {\"Year of Record\" : \"Year\",\n",
        "                                   \"Size of City\" : \"CitySize\",\n",
        "                                   \"University Degree\" : \"Degree\",\n",
        "                                   \"Wears Glasses\" : \"Glasses\",\n",
        "                                   \"Hair Color\" : \"Hair\",\n",
        "                                   \"Body Height [cm]\" : \"Height\",\n",
        "                                   \"Income in EUR\" : \"Income\"},\n",
        "                        inplace = True)\n",
        "\n",
        "print (datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoUmGfOWuKnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look again \n",
        "incomeknown_df.tail(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATtz3Q61nyD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and unknowns\n",
        "incomeunknown_df.tail(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nTndBoG5JsE",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "_Initial data exploration_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAOfl9Ne5Tjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomeknown_df.describe()\n",
        "\n",
        "# data is sort of crappy - normally if data doesn't make sense you question sources\n",
        "# outliers - negative income - 14 age 115 age -  5M income \n",
        "# glasses almost exactly 50% ! - but does it correlate?  check later\n",
        "\n",
        "# missing data in Year -- choose mean ?\n",
        "\n",
        "# missing data in age -- impute with mice ?\n",
        "# and do year the same way as well?\n",
        "\n",
        "# need to check the missings in unknown - would be a bit mean to \n",
        "# have missings in other cols there"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj5PHYvapusr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomeunknown_df.describe()\n",
        "\n",
        "# years and age also missing but in slightly different proportions\n",
        "# others still all present - and comparable ranges - \n",
        "\n",
        "# note age outlier - older than any recorded human - \n",
        "# cannot treat data as real - just an academic exercise - or noise added very poorly.\n",
        "\n",
        "# ok the numeric data is workable - still no view on whether it is good enough to give a result\n",
        "\n",
        "# replacing missing data should be carried out across the entire data set \n",
        "# and not include the known income - this is just circular and makes the test/train more different! "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rppnPQ4ymIvC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxS34kwLsFUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and the categorical data :\n",
        "incomeknown_df[['Gender','Country','Profession','Degree','Hair']].describe()\n",
        "\n",
        "# a lot of missing data in Gender - and 5 values present - confirm the '3' are equal \n",
        "# - so check for 'rainbow' corelations\n",
        "# treat missing as a 4th and check its correlation as well \n",
        "\n",
        "# Country - all present - note most frequent is a 'small' country \n",
        "# very wide range of categories here - treatment to be considered.\n",
        "# but if it does contribute then how we encode it matters\n",
        "# impractical to distribute across n features (as in 1-hot etc)\n",
        "# no clear order determinable so a subset mean mechanism like James-Stein\n",
        "# might work well - very tempting to consider encoding to two features\n",
        "# mean and sd based - for any regression approach a mean^2 feature may help  \n",
        "# looks like a ryo encoder - bah\n",
        "\n",
        "# profession looks similar - with a few missing \n",
        "\n",
        "# (note from below - clearly artificial) \n",
        "# alphabetic application used - how does it correlate ?\n",
        "\n",
        "# how about a James-Stein encoding in one feature and an additional \n",
        "# 1 hot encoding on the initial letter making 27 features (is this too many?) \n",
        "\n",
        "# degree - has missings and 5 levels - do missing simply constitute a 6th?\n",
        "\n",
        "# hair - same\n",
        "\n",
        "# check corelation - do missing actually make a feature ?\n",
        "# 1 hot would do this and treat missing seperately.\n",
        "\n",
        "# looking like about 50 wide at this point - too many dimensions\n",
        "# really need to know how they matter.\n",
        "\n",
        "# cpu and time are not an issue - just plug on \n",
        "# in real life I'd say go back and get good data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eULCQbzD7Bcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and the unknowns\n",
        "incomeunknown_df[['Gender','Country','Profession','Degree','Hair']].describe()\n",
        "# similar Gender - but confirm the '3' match \n",
        "# and similar for Degree and Hair - critical to confirm the category match \n",
        "\n",
        "# Country and Profession - note another 'small' country and also the 'p' profession\n",
        "\n",
        "# fewer countries and professions - but are there any in unknown that don't \n",
        "# exist in known - if so need to consider how to manage them for the encoding strategy\n",
        "# sort of crappy problem - not the same as missing - not sure what to do\n",
        "# except hope the answer is 'no' !\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXbiPY30qOUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at the categorical data \n",
        "print ( incomeknown_df['Profession'].value_counts() )\n",
        "\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Profession == 'other'] ) )\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Profession == 'Other'] ) )\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Profession == 'Unknown'] ) )\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Profession == 'unknown'] ) )\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Profession == '0'] ) )\n",
        "\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Profession.isna()] ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAlHGCzJAdTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ( incomeknown_df['Country'].value_counts() )\n",
        "\n",
        "\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Country == 'other'] ) )\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Country == 'Other'] ) )\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Country == 'Unknown'] ) )\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Country == 'unknown'] ) )\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Country == '0'] ) )\n",
        "\n",
        "print (len ( incomeknown_df.loc[incomeknown_df.Country.isna()] ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkzNAc40qP8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "print ( incomeknown_df['Degree'].value_counts() )\n",
        "\n",
        "print ( incomeknown_df['Hair'].value_counts() )\n",
        "\n",
        "\n",
        "print ( incomeknown_df['Gender'].value_counts() )\n",
        "\n",
        "# note the highly artificial nature of the data \n",
        "# professions starting with p dominate the high frequencies\n",
        "# along with a few q and r\n",
        "# whereas those beginning with a, b or c dominate the lower frequencies.\n",
        "# James Stein encoding - or a variant of it based on target mean may work well for this.\n",
        "\n",
        "# if there is something silly going on such as the real feature being the initial letter then \n",
        "# this will still work - need to be be careful with the singletons.\n",
        "\n",
        "# countries have no apparent pattern - treat as above.\n",
        "# would be interesting to look at a mean and sd pair of features\n",
        "# do we need to ammend with mean and sd of entire known sample?\n",
        "# seems like that is weakening the feature - depends on its corelation with the result.\n",
        "\n",
        "# comforting that Loas (see above) is high here - looks like semi-randomeness\n",
        "\n",
        "# Real put-up job - 'analyse this, sucker!'\n",
        "\n",
        "# sort of fishing in the dark here - the number of categories are very high.\n",
        "# grouping them may be a better approach - but don't like that idea very much.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ2XsqA83IU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and the unknowns \n",
        "\n",
        "print ( incomeunknown_df['Profession'].value_counts() )\n",
        "\n",
        "print ( incomeunknown_df['Degree'].value_counts() )\n",
        "\n",
        "print ( incomeunknown_df['Hair'].value_counts() )\n",
        "\n",
        "print ( incomeunknown_df['Country'].value_counts() )\n",
        "\n",
        "print ( incomeunknown_df['Gender'].value_counts() )\n",
        "\n",
        "# really critical to know if there are any categorical values in unknowns that \n",
        "# are not present in knowns - and work out how to manage them.\n",
        "\n",
        "# first need to work out if they exist - how ?\n",
        "\n",
        "# - see France - doesn't look good - could well be categories unique to unknowns.\n",
        "\n",
        "# Profession - the 'p' and (o) effect continues\n",
        "# as does the abc at the bottom - and a '.' sneaked in !\n",
        "\n",
        "# Degree and Hair are similar but both exhibit a switch in frequency order.\n",
        "# In both cases the counts are close - but doesn't give\n",
        "# confidence in the train test selection.\n",
        "\n",
        "# real world - you can't always sample from the full population \n",
        "# but you need to know if you haven't.\n",
        "\n",
        "# overall this is sort of crappy date - and I suspect that there \n",
        "# has been noise added and (see below on non-male/female) clearly some\n",
        "# explicitely normal data inserted.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mTR5COj7FxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare some simple histograms and scatter plots of numeric data against income\n",
        "# looking for any obvious correlation\n",
        "\n",
        "# exclude outliers (particulalry high incomes) to make the plots more useful\n",
        "\n",
        "# \n",
        "\n",
        "# incomeknown_df.hist(\"Year\", bins=40)\n",
        "# incomeknown_df.loc[incomeknown_df.Income < 1000000].plot.scatter(x = \"Year\", y = \"Income\")\n",
        "\n",
        "# print (\"Scater plot of Income by Year\")\n",
        "plt.scatter(incomeknown_df.loc[incomeknown_df.Income < 60000][\"Year\"], incomeknown_df.loc[incomeknown_df.Income < 60000][\"Income\"], alpha=0.0075)\n",
        "plt.title('Scatter plot of Income by Year')\n",
        "\n",
        "incomeknown_df.loc[incomeknown_df.Income < 500000].hist(\"Income\", bins=300)\n",
        "\n",
        "# Age\n",
        "\n",
        "incomeknown_df.hist(\"Age\", bins=60)\n",
        "incomeknown_df.loc[incomeknown_df.Income < 100000].plot.scatter(x = \"Age\", y = \"Income\", alpha=0.05)\n",
        "\n",
        "# Height\n",
        "\n",
        "incomeknown_df.hist(\"Height\", bins=200)\n",
        "incomeknown_df.loc[incomeknown_df.Income < 100000].plot.scatter(x = \"Height\", y = \"Income\", alpha=0.005)\n",
        "\n",
        "# height and Gender\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                  (incomeknown_df.Gender == \"male\")].hist(\"Height\", bins=300)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                   (incomeknown_df.Gender == \"male\")].plot.scatter(x = \"Height\", y = \"Income\", c=\"LightBlue\", alpha=0.01)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                   (incomeknown_df.Gender == \"female\")].hist(\"Height\", bins=300)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                   (incomeknown_df.Gender == \"female\")].plot.scatter(x = \"Height\", y = \"Income\", c = 'Pink', alpha=0.01)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                   ((incomeknown_df.Gender != \"female\") & (incomeknown_df.Gender != \"male\"))].hist(\"Height\", bins=300)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                   ((incomeknown_df.Gender != \"female\") & (incomeknown_df.Gender != \"male\"))].plot.scatter(x = \"Height\", y = \"Income\", c = 'Grey', alpha=0.02)\n",
        "\n",
        "# CitySize\n",
        "incomeknown_df.hist(\"CitySize\", bins=60)\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 200000) & (incomeknown_df.CitySize < 500000)].plot.scatter(x = \"CitySize\", y = \"Income\", alpha=0.01)\n",
        "\n",
        " \n",
        "\n",
        "# found a correlation on year linear or slightly x^2 - add a feature year ^2 ?\n",
        "\n",
        "# income - 'skewed-normal' dist\n",
        "\n",
        "# height shows an artificial factor adding to a normal dist - off-centre\n",
        "\n",
        "# feamale and male height look normal \n",
        "# non gender height is artificial and even distribution between bounds.\n",
        "# not sure what this means yet.\n",
        "\n",
        "# all income distrubutions over height appear normal \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oah27qIawPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examine CitySize - odd break around 100K\n",
        "\n",
        "print(len(incomeknown_df.loc[(incomeknown_df.CitySize < 100000)]),\n",
        "      incomeknown_df.loc[(incomeknown_df.CitySize < 100000)].Income.mean())\n",
        "\n",
        "\n",
        "print(len(incomeknown_df.loc[(incomeknown_df.CitySize == 100000)]),\n",
        "      incomeknown_df.loc[(incomeknown_df.CitySize == 100000)].Income.mean())\n",
        "\n",
        "print(len(incomeknown_df.loc[(incomeknown_df.CitySize > 100000)]),\n",
        "      incomeknown_df.loc[(incomeknown_df.CitySize > 100000)].Income.mean())\n",
        "\n",
        "# interesting - let's add a feature to pick this up simple 1 for >100 0 otherwise\n",
        "# will help a regression grab this difference"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb6UWQ817Q45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# do the same for unknowns - (with out the corelation incomew !) \n",
        "\n",
        "\n",
        "incomeunknown_df.hist(\"Height\", bins=200)\n",
        "\n",
        "# Height - same pattern of artificial even distribution added to normal\n",
        "\n",
        "incomeunknown_df.loc[(incomeunknown_df.Gender == \"male\")].hist(\"Height\", bins=300)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Gender == \"female\")].hist(\"Height\", bins=300)\n",
        "\n",
        "incomeknown_df.loc[((incomeknown_df.Gender != \"female\") & (incomeknown_df.Gender != \"male\"))].hist(\"Height\", bins=300)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pYM3PXD-7NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at some outliers \n",
        "\n",
        "# In colab print() clips wide data - direct output produces better output \n",
        "# - but only 1 can be used per block\n",
        "# print(incomeknown_df.loc[incomeknown_df.Age > 110])\n",
        "# print(incomeknown_df.loc[incomeknown_df.Income > 2500000])\n",
        "\n",
        "incomeknown_df.loc[incomeknown_df.Age > 108]\n",
        "# incomeknown_df.loc[incomeknown_df.Income > 2500000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhxJ6NSOeZ-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomeknown_df.loc[incomeknown_df.Income > 2250000]\n",
        "\n",
        "# note the lower case professions in the p q r s t u range \n",
        "# and upper case A\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5FukPgIhjMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomeknown_df.loc[incomeknown_df.Income < -3000]\n",
        "# note no p q r s t u  amongst lowest (negative) incomes - despite being the most frequent \n",
        "# so there is a clear effect here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCHCP9cC9-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OK time to try and start fixing data and make a working set \n",
        "# suitable for feature engineering \n",
        "\n",
        "# Lets look at gender\n",
        "\n",
        "# Need some charts of Gender correlations for the non male / female  and misisng \n",
        "# can we just call these all a third group 'other' or do we need more\n",
        "\n",
        "print ( len( incomeknown_df[['Gender']] ) )\n",
        "print ( incomeknown_df[['Gender']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeknown_df['Gender'].value_counts() )\n",
        "\n",
        "print (\"\\n\")\n",
        "\n",
        "\n",
        "# lets look at mean and sd for the non male / female and see how many distinct \n",
        "# categories exist.\n",
        "print (\"gender, count, mean, st dev\")\n",
        "\n",
        "gencount = 0\n",
        "gendr = \"male\"\n",
        "print ( gendr,\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.std())\n",
        "gencount += incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.count()\n",
        "\n",
        "gendr = \"female\"\n",
        "print ( gendr,\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.std())\n",
        "gencount += incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.count()\n",
        "\n",
        "gendr = \"other\"\n",
        "print ( gendr,\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.std())\n",
        "gencount += incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.count()\n",
        "\n",
        "gendr = \"unknown\"\n",
        "print ( gendr,\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.std())\n",
        "gencount += incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.count()\n",
        "\n",
        "gendr = \"0\"\n",
        "print ( gendr,\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.std())\n",
        "gencount += incomeknown_df.loc[incomeknown_df.Gender == gendr].Income.count()\n",
        "\n",
        "gendr = \".isnull()\"\n",
        "print ( gendr,\n",
        "        incomeknown_df.loc[incomeknown_df.Gender.isnull()].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender.isnull()].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Gender.isnull()].Income.std())\n",
        "gencount += incomeknown_df.loc[incomeknown_df.Gender.isnull()].Income.count()\n",
        "\n",
        "print (gencount)\n",
        "print (\"\\n\")\n",
        "\n",
        "# OK got 'em all\n",
        "\n",
        "# just confirm we can get them all in unknowns - obviously without the \n",
        "# income data\n",
        "\n",
        "\n",
        "print ( len( incomeunknown_df[['Gender']] ) )\n",
        "print ( incomeunknown_df[['Gender']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeunknown_df['Gender'].value_counts() )\n",
        "print (\"\\n\")\n",
        "print (\"gender, count\")\n",
        "\n",
        "gencount = 0\n",
        "gendr = \"male\"\n",
        "print ( gendr,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Gender == gendr].Instance.count())\n",
        "gencount += incomeunknown_df.loc[incomeunknown_df.Gender == gendr].Instance.count()\n",
        "\n",
        "gendr = \"female\"\n",
        "print ( gendr,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Gender == gendr].Instance.count())\n",
        "gencount += incomeunknown_df.loc[incomeunknown_df.Gender == gendr].Instance.count()\n",
        "\n",
        "gendr = \"other\"\n",
        "print ( gendr,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Gender == gendr].Instance.count())\n",
        "gencount += incomeunknown_df.loc[incomeunknown_df.Gender == gendr].Instance.count()\n",
        "\n",
        "gendr = \"unknown\"\n",
        "print ( gendr,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Gender == gendr].Instance.count())\n",
        "gencount += incomeunknown_df.loc[incomeunknown_df.Gender == gendr].Instance.count()\n",
        "\n",
        "gendr = \"0\"\n",
        "print ( gendr,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Gender == gendr].Instance.count())\n",
        "gencount += incomeunknown_df.loc[incomeunknown_df.Gender == gendr].Instance.count()\n",
        "\n",
        "gendr = \".isnull()\"\n",
        "print ( gendr,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Gender.isnull()].Instance.count())\n",
        "gencount += incomeunknown_df.loc[incomeunknown_df.Gender.isnull()].Instance.count()\n",
        "\n",
        "print (gencount)\n",
        "print (\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn7iDwuIjxz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OK fixing Gender : \n",
        "\n",
        "# other and unknown look similar  - 0 and null not quite so \n",
        "# very tempting to keep them all - however for simplicity we'll just encode as \n",
        "# other (adding in unknown) and none (for 0 and null) so 4 catgories\n",
        "\n",
        "# or keep them all - better, they don't overlap well\n",
        "# other , unknown , none1, none2\n",
        "\n",
        "incomeknown_df.Gender.replace(\"0\",\"none1\", inplace=True)\n",
        "incomeknown_df.Gender.fillna(\"none2\", inplace=True)\n",
        "print ( incomeknown_df[['Gender']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeknown_df['Gender'].value_counts() )\n",
        "print (\"\\n\")\n",
        "incomeunknown_df.Gender.replace(\"0\",\"none1\", inplace=True)\n",
        "incomeunknown_df.Gender.fillna(\"none2\", inplace=True)\n",
        "print ( incomeunknown_df[['Gender']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeunknown_df['Gender'].value_counts() )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxtAMQc-rosd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# do the same thing with Hair \n",
        "\n",
        "print ( len( incomeknown_df[['Hair']] ) )\n",
        "print ( incomeknown_df[['Hair']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeknown_df['Hair'].value_counts() )\n",
        "\n",
        "print (\"\\n\")\n",
        "\n",
        "\n",
        "# lets look at mean and sd for eash and see how many distinct \n",
        "# categories exist.\n",
        "haircount = 0\n",
        "haircol = \"Black\"\n",
        "print ( haircol,\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.std())\n",
        "haircount += incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count()\n",
        "\n",
        "haircol = \"Blond\"\n",
        "print ( haircol,\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.std())\n",
        "haircount += incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count()\n",
        "\n",
        "haircol = \"Brown\"\n",
        "print ( haircol,\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.std())\n",
        "haircount += incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count()\n",
        "\n",
        "haircol = \"Red\"\n",
        "print ( haircol,\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.std())\n",
        "haircount += incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count()\n",
        "\n",
        "haircol = \"Unknown\"\n",
        "print ( haircol,\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.std())\n",
        "haircount += incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count()\n",
        "\n",
        "haircol = \"0\"\n",
        "print ( haircol,\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.std())\n",
        "haircount += incomeknown_df.loc[incomeknown_df.Hair == haircol].Income.count()\n",
        "\n",
        "haircol = \".isnull()\"\n",
        "print ( haircol,\n",
        "        incomeknown_df.loc[incomeknown_df.Hair.isnull()].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair.isnull()].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Hair.isnull()].Income.std())\n",
        "haircount += incomeknown_df.loc[incomeknown_df.Hair.isnull()].Income.count()\n",
        "\n",
        "print (haircount)\n",
        "print (\"\\n\")\n",
        "\n",
        "# OK got 'em all\n",
        "\n",
        "# just confirm we can get them all in unknowns - obviously without the \n",
        "# income data\n",
        "\n",
        "\n",
        "print ( len( incomeunknown_df[['Hair']] ) )\n",
        "print ( incomeunknown_df[['Hair']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeunknown_df['Hair'].value_counts() )\n",
        "\n",
        "haircount = 0\n",
        "haircol = \"Black\"\n",
        "print ( haircol,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count())\n",
        "haircount += incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count()\n",
        "\n",
        "haircol = \"Blond\"\n",
        "print ( haircol,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count())\n",
        "haircount += incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count()\n",
        "\n",
        "haircol = \"Brown\"\n",
        "print ( haircol,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count())\n",
        "haircount += incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count()\n",
        "\n",
        "\n",
        "haircol = \"Red\"\n",
        "print ( haircol,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count())\n",
        "haircount += incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count()\n",
        "\n",
        "haircol = \"Unknown\"\n",
        "print ( haircol,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count())\n",
        "haircount += incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count()\n",
        "\n",
        "haircol = \"0\"\n",
        "print ( haircol,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count())\n",
        "haircount += incomeunknown_df.loc[incomeunknown_df.Hair == haircol].Instance.count()\n",
        "\n",
        "haircol = \".isnull()\"\n",
        "print ( haircol,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Hair.isnull()].Instance.count())\n",
        "haircount += incomeunknown_df.loc[incomeunknown_df.Hair.isnull()].Instance.count()\n",
        "\n",
        "print (haircount)\n",
        "print (\"\\n\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "992UdE6LjrNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OK fixing Hair : \n",
        "\n",
        "# null looks like Black - \n",
        "# very tempting to keep them all - however for simplicity we'll just encode as \n",
        "# \n",
        "\n",
        "# or keep them all - better, they don't overlap well\n",
        "#  unknown , unknown1, unknown2\n",
        "\n",
        "incomeknown_df.Hair.replace(\"0\",\"Unknown1\", inplace=True)\n",
        "incomeknown_df.Hair.fillna(\"Unknown2\", inplace=True)\n",
        "print ( incomeknown_df[['Hair']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeknown_df['Hair'].value_counts() )\n",
        "print (\"\\n\")\n",
        "incomeunknown_df.Hair.replace(\"0\",\"Unknown1\", inplace=True)\n",
        "incomeunknown_df.Hair.fillna(\"Unknown2\", inplace=True)\n",
        "print ( incomeunknown_df[['Hair']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeunknown_df['Hair'].value_counts() )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_qCiA3MBWKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and with Degree\n",
        "\n",
        "\n",
        "print ( len( incomeknown_df[['Degree']] ) )\n",
        "print ( incomeknown_df[['Degree']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeknown_df['Degree'].value_counts() )\n",
        "\n",
        "print (\"\\n\")\n",
        "\n",
        "\n",
        "# lets look at mean and sd for eash and see how many distinct \n",
        "# categories exist.\n",
        "degcount = 0\n",
        "degre = \"Bachelor\"\n",
        "print ( degre,\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.std())\n",
        "degcount += incomeknown_df.loc[incomeknown_df.Degree == degre].Income.count()\n",
        "\n",
        "degre = \"Master\"\n",
        "print ( degre,\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.std())\n",
        "degcount += incomeknown_df.loc[incomeknown_df.Degree == degre].Income.count()\n",
        "\n",
        "degre = \"PhD\"\n",
        "print ( degre,\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.std())\n",
        "degcount += incomeknown_df.loc[incomeknown_df.Degree == degre].Income.count()\n",
        "\n",
        "degre = \"No\"\n",
        "print ( degre,\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.std())\n",
        "degcount += incomeknown_df.loc[incomeknown_df.Degree == degre].Income.count()\n",
        "\n",
        "degre = \"0\"\n",
        "print ( degre,\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree == degre].Income.std())\n",
        "degcount += incomeknown_df.loc[incomeknown_df.Degree == degre].Income.count()\n",
        "\n",
        "degre = \".isnull()\"\n",
        "print ( degre,\n",
        "        incomeknown_df.loc[incomeknown_df.Degree.isnull()].Income.count(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree.isnull()].Income.mean(),\n",
        "        incomeknown_df.loc[incomeknown_df.Degree.isnull()].Income.std())\n",
        "degcount += incomeknown_df.loc[incomeknown_df.Degree.isnull()].Income.count()\n",
        "\n",
        "print (degcount)\n",
        "print (\"\\n\")\n",
        "\n",
        "# OK got 'em all\n",
        "\n",
        "# just confirm we can get them all in unknowns - obviously without the \n",
        "# income data\n",
        "\n",
        "\n",
        "print ( len( incomeunknown_df[['Degree']] ) )\n",
        "print ( incomeunknown_df[['Degree']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeunknown_df['Degree'].value_counts() )\n",
        "\n",
        "degcount = 0\n",
        "degre = \"Bachelor\"\n",
        "print ( degre,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Degree == degre].Instance.count())\n",
        "degcount += incomeunknown_df.loc[incomeunknown_df.Degree == degre].Instance.count()\n",
        "\n",
        "degre = \"Master\"\n",
        "print ( degre,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Degree == degre].Instance.count())\n",
        "degcount += incomeunknown_df.loc[incomeunknown_df.Degree == degre].Instance.count()\n",
        "\n",
        "degre = \"PhD\"\n",
        "print ( degre,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Degree == degre].Instance.count())\n",
        "degcount += incomeunknown_df.loc[incomeunknown_df.Degree == degre].Instance.count()\n",
        "\n",
        "\n",
        "degre = \"No\"\n",
        "print ( degre,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Degree == degre].Instance.count())\n",
        "degcount += incomeunknown_df.loc[incomeunknown_df.Degree == degre].Instance.count()\n",
        "\n",
        "degre = \"0\"\n",
        "print ( degre,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Degree == degre].Instance.count())\n",
        "degcount += incomeunknown_df.loc[incomeunknown_df.Degree == degre].Instance.count()\n",
        "\n",
        "degre = \".isnull()\"\n",
        "print ( degre,\n",
        "        incomeunknown_df.loc[incomeunknown_df.Degree.isnull()].Instance.count())\n",
        "degcount += incomeunknown_df.loc[incomeunknown_df.Degree.isnull()].Instance.count()\n",
        "\n",
        "print (degcount)\n",
        "print (\"\\n\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMXDdlGHkOJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OK Fixing Degree\n",
        "\n",
        "# The different non-degrees look quite different - \n",
        "# again we keep them all\n",
        "# unknown1, unknown2\n",
        "\n",
        "incomeknown_df.Degree.replace(\"0\",\"Unknown1\", inplace=True)\n",
        "incomeknown_df.Degree.fillna(\"Unknown2\", inplace=True)\n",
        "print ( incomeknown_df[['Degree']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeknown_df['Degree'].value_counts() )\n",
        "print (\"\\n\")\n",
        "incomeunknown_df.Degree.replace(\"0\",\"Unknown1\", inplace=True)\n",
        "incomeunknown_df.Degree.fillna(\"Unknown2\", inplace=True)\n",
        "print ( incomeunknown_df[['Degree']].describe() )\n",
        "print (\"\\n\")\n",
        "print ( incomeunknown_df['Degree'].value_counts() )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-9WgHUye6XZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with professions we just need to fill the nulls\n",
        "# since we have so many adding an extra one is no harm\n",
        "# but use an upper case initial letter as there is something going on with \n",
        "# the fequency of initial letters in profession\n",
        "\n",
        "# do any begin with \"U\" ?\n",
        "\n",
        "# below only works after nulls are fixed\n",
        "\n",
        "# for prof in incomeknown_df.Profession.unique() :\n",
        "#   if prof[0] ==\"U\" :\n",
        "#     print (prof)\n",
        "\n",
        "# No \n",
        "\n",
        "# do any begin with uppercase ?\n",
        "\n",
        "# for prof in incomeknown_df.Profession.unique() :\n",
        "#  if prof[0] <= \"Z\" :\n",
        "#    print (prof)\n",
        "    \n",
        "# YES mostly A B & C (one O and 1 H)\n",
        "# also note the \".\"\n",
        "\n",
        "\n",
        "print ( len( incomeknown_df[['Profession']] ) )\n",
        "print ( incomeknown_df[['Profession']].describe() )\n",
        "\n",
        "print ( len( incomeunknown_df[['Profession']] ) )\n",
        "print ( incomeunknown_df[['Profession']].describe() )\n",
        "\n",
        "# and identify any in the unknowns which are not in the knowns.\n",
        "# need to code this .....\n",
        "\n",
        "# incomeunknown_df.Profession.replace(\"Unknown2\",\"Unknown\", inplace=True)\n",
        "\n",
        "for prof in incomeunknown_df.Profession.unique() :\n",
        "  # print ( prof )\n",
        "  # print ( type(prof) ) \n",
        "  \n",
        "  if len(incomeknown_df.loc[(incomeknown_df.Profession == prof)]) == 0 :\n",
        "    print ( prof , \n",
        "           len(incomeknown_df.loc[(incomeknown_df.Profession == prof)]) , \n",
        "           len(incomeunknown_df.loc[(incomeunknown_df.Profession == prof)]) )\n",
        "\n",
        "# there are 11 over 21 samples \n",
        "# not surprisingly all beginning with a, b or c\n",
        "\n",
        "# what to do here ? - need the initial letter correlation with income to \n",
        "# help make a decision.\n",
        "\n",
        "# if mean based then use overall mean - but if using hot-1 on initial letter the\n",
        "# need to substitute these to make it easier.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaqdJfalrLOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fixing professions :\n",
        "\n",
        "incomeknown_df.Profession.fillna(\"Unknown\", inplace=True)\n",
        "incomeunknown_df.Profession.fillna(\"Unknown\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bniOzjMPWmmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# no need to fix countries all present \n",
        "# but is there a country in the unknowns that is not in the knowns\n",
        "\n",
        "# print ( incomeknown_df['Country'].value_counts() )\n",
        "# type( incomeknown_df['Country'].value_counts() )\n",
        "# print ( \"in known\" )\n",
        "# print(incomeknown_df[incomeknown_df.Country == \"Malawi\"])\n",
        "# print ( \"in unknown\" )\n",
        "# print(incomeunknown_df[incomeknown_df.Country == \"Malawi\"])\n",
        "\n",
        "for ctry in incomeunknown_df.Country.unique() :\n",
        "  # print ( ctry )\n",
        "  # print ( type(ctry) ) \n",
        "  \n",
        "  if len(incomeknown_df.loc[(incomeknown_df.Country == ctry)]) == 0 :\n",
        "    print ( ctry , \n",
        "           len(incomeknown_df.loc[(incomeknown_df.Country == ctry)]) , \n",
        "           len(incomeunknown_df.loc[(incomeunknown_df.Country == ctry)]) )\n",
        "    \n",
        "# there are 6 of these covering 10 samples = we need to do something with them \n",
        "# very tempting to just dump them into another 'middle-ish country'\n",
        "# but better to look ahead to the encoding - if we use a mean based encoding \n",
        "# then these can map to the overall mean.\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyhjSnTaoMgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fixing Age and Year\n",
        "\n",
        "# just using mean for both \n",
        "# need to get past exploration and on to feature engineering now\n",
        "\n",
        "incomeknown_df.Age.fillna(37.0, inplace=True)\n",
        "incomeunknown_df.Age.fillna(37.0, inplace=True)\n",
        "\n",
        "incomeknown_df.Year.fillna(1999.0, inplace=True)\n",
        "incomeunknown_df.Year.fillna(1999.0, inplace=True)\n",
        "\n",
        "# Ok so here we have complete data - and we know a lot about it \n",
        "# but we havn't engineered any features yet\n",
        "# and we haven't done any encoding\n",
        "# save and implement some feature engineering"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tadXOwjUsgMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# repeat the general outputs to verify counts etc.\n",
        "incomeknown_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7DKANuTsubT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomeunknown_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYREi8b4s3Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomeknown_df[['Gender','Country','Profession','Degree','Hair']].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fUEVYUCtAHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomeunknown_df[['Gender','Country','Profession','Degree','Hair']].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piKBEHxxtFP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OK - time to do some fixing.\n",
        "\n",
        "# don't like the outliers lets kill a few \n",
        "\n",
        "# income outliers are going to mess up a lot of things\n",
        "# but it's a bit scary changing the answer\n",
        "\n",
        "# how to chnage a value base on its existing value ?\n",
        "\n",
        "# going to replace all incomes above 500K with 500K\n",
        "\n",
        "# df.loc[<row selection>, <column selection>]\n",
        "\n",
        "print ( len (incomeknown_df.loc[incomeknown_df.Income > 1999999] ))\n",
        "print ( len (incomeknown_df.loc[incomeknown_df.Income > 2000000] ))\n",
        "print(\"clipping outliers\")\n",
        "\n",
        "incomeknown_df.loc[incomeknown_df.Income > 2000000, 'Income'] = 2000000\n",
        "\n",
        "print ( len (incomeknown_df.loc[incomeknown_df.Income > 1999999] ))\n",
        "print ( len (incomeknown_df.loc[incomeknown_df.Income > 2000000] ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu9oLz_slSY0",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adqBJ-dHP9BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"def predict(X, theta)\")\n",
        "def predict(X, theta):\n",
        "  # takes m by n matrix X as input and returns an m by 1 vector \n",
        "  # containing the predictions h_theta(x^i) for each row x^i, i=1,...,m in X\n",
        "  ##### replace the next line with your code #####\n",
        "  \n",
        "  # This is the generic multiple variable implementation. \n",
        "  \n",
        "  # For conveniece each data point in X has an initial 1 \n",
        "  #   added to enable the B0 coeficient to be applied efficiently\n",
        "  \n",
        "  # print(X)\n",
        "  # print(theta)\n",
        "  # print(X.shape)\n",
        "  \n",
        "  # Get the number of coeficients B0, B1 ..... \n",
        "  #   we iterate over these\n",
        "  n=len(theta)\n",
        "  \n",
        "  # For the multiple linear regression we need to iterate over the \n",
        "  #   length of theta \n",
        "  # This assumes a simple B0 + B1.X1 + B2.X2 + ....\n",
        "  #   it does not consider more complex dependencies\n",
        "  #   such as B0 + B1.X1 + B2.X2 + B3.X1.X2   etc.\n",
        "  #   these require the X to be constructed to meet the requirement\n",
        "  #   and may introduce too much colinearity.\n",
        "  \n",
        "  # Check for single data point\n",
        "  #   requires a special case as it arrives as 1D, rather than 2D\n",
        "  #   and if it does arrive as 2D the else handles it anyway\n",
        "  \n",
        "  # Numpy doesn't appear to support a mechanism to directly \n",
        "  #   multiply each row of an array by an equivalent sized vector\n",
        "  #   so we use a for loop to iterate over the vector but use \n",
        "  #   numpy maths, which are more efficient, to apply each element\n",
        "  #   of the theta vetor to the equivalent data variable for all points. \n",
        "   \n",
        "  if len(X.shape) == 1 : \n",
        "    # this is the edge case for a single data point in a vector\n",
        "    pred = X[0] * theta[0] \n",
        "    for i in range(1,n) :\n",
        "      pred = pred + X[i]*theta[i]  \n",
        "        \n",
        "  else : \n",
        "    #this is the general case for data point(s) in an array\n",
        "    pred = X[:,0]*theta[0] \n",
        "    for i in range(1,n) :\n",
        "      pred = pred + X[:,i]*theta[i]    \n",
        "        \n",
        "  # print(pred)\n",
        "  \n",
        "  # Return the prediction\n",
        "  # The returned value is a vector of value for each data point.\n",
        "  return pred\n",
        "# end def predict\n",
        "\n",
        "\n",
        "print(\"def computeCost(X, y, theta)\")\n",
        "def computeCost(X, y, theta):\n",
        "  # function calculates the cost J(theta) and return its value\n",
        "  ##### replace the next line with your code #####\n",
        "  \n",
        "  # this function is already independent of the number of variables\n",
        "  # provided the X array carries the data with a leading 1 on each data point\n",
        "  # and the theta has the same number of B0, B1, B2 ...  values.\n",
        "  \n",
        "  # Get the value(s) predicted by the current theta values\n",
        "  costpred = predict (X,theta)\n",
        "  \n",
        "  # get the difference(s) between the predictions and the actuals\n",
        "  costbase = costpred - y\n",
        "    \n",
        "  # get the square of the difference(s)\n",
        "  costsq = costbase **2\n",
        "  \n",
        "  # get the sum of the squared difference(s)\n",
        "  sumcost = costsq.sum() \n",
        "  \n",
        "  # divide the sum of squares by twice the number of data points\n",
        "  cost = sumcost/(2*len(y))  \n",
        "  \n",
        "  # return the cost of the current theta values\n",
        "  # the returned value is a numeric value of the cost.\n",
        "  return cost\n",
        "# end def computeCost\n",
        "\n",
        "\n",
        "\n",
        "print(\"def computeGradient(X, y, theta)\")\n",
        "def computeGradient(X, y, theta):\n",
        "  # function calulate the gradient of J(theta) and returns its value\n",
        "  ##### replace the next line with your code #####\n",
        "  # This function is already capable of delaing with multiple varables\n",
        "  # provided X (with a leading 1 per data point) and theta are matched sizes.\n",
        "  \n",
        "  # number of coeficients\n",
        "  n=len(theta)\n",
        "  # initiate the result\n",
        "  grad = np.zeros(n)\n",
        "  \n",
        "  # print (\"Number of coeficients: \" , n)\n",
        "  # print (\"Shapes of data, result and theta : \" , X.shape, y.shape, theta.shape)\n",
        "  # print (\"Types of  data, result and theta : \" , type(X), type(y), type(theta))\n",
        "  # print (\"Sample head of data\")\n",
        "  # for i in range(5) :\n",
        "      # print (X[i,:])\n",
        "    \n",
        "  # Get the value predicted by the current theta values\n",
        "  costpred = predict (X,theta)\n",
        "  # print (\"Compute Grad #2 :\", costpred.shape)\n",
        "  \n",
        "  # get the difference between the predictions and the actuals\n",
        "  costbase = costpred - y\n",
        "  # print (\"Compute Grad #3 :\", costbase.shape)  \n",
        "  \n",
        "  # calculate the gradient for each coefficient\n",
        "  # for is inefficient but it is used to iterate over a small\n",
        "  # range (1 more than the number of variables \n",
        "  # i.e the number of coefficients)\n",
        "  # while numpy array maths are used for the larger dimension\n",
        "  # (the number of data points)\n",
        "  for i in range(n) :\n",
        "    # get product of differences by current coeficients data point\n",
        "    costprod = costbase * X[:,i]\n",
        "    # print (\"Compute Grad #4 :\", costprod.shape) \n",
        "    # get the sum of the cost products\n",
        "    costprodsum = costprod.sum()\n",
        "    # print (\"Compute Grad #5 :\", costprodsum)\n",
        "    # divide by the number of data points\n",
        "    grad[i] = costprodsum / len(y)\n",
        "    # take this outside the for loop and use numpy maths ! \n",
        "    # print (\"Compute Grad #6 :\", grad[i])\n",
        "  # end for\n",
        "  # print (\"Compute Grad #6 :\", grad)\n",
        "  \n",
        "  # return the gradient\n",
        "  # the returned value of a vector of a gradient for each coeficient (theta) \n",
        "  return grad\n",
        "# end def computeGradient\n",
        "\n",
        "\n",
        "print(\"def gradDescent(X, y, theta, iters, alpha)\")\n",
        "def gradDescent(X, y, theta, iters, alpha):\n",
        "  # X - data (with the extra 1s in col 1)\n",
        "  # y - results - vector with 1 resilt per data point\n",
        "  # theta - B0, B1, B2 ... starting values \n",
        "  # iters - how many iterations\n",
        "  # alpha - adjustor for size of adjustment per step\n",
        "  \n",
        "  # returns : \n",
        "  # theta - B0, B1, B2 ... final values \n",
        "  # cost - cost after each iteration\n",
        "  \n",
        "  # initialize cost array\n",
        "  cost = np.zeros(iters)\n",
        "  \n",
        "  for i in range(iters):\n",
        "    theta = theta - alpha * computeGradient(X,y,theta)\n",
        "    cost[i] = computeCost(X, y, theta)\n",
        "\n",
        "  return theta, cost\n",
        "# end def gradientDescent   \n",
        "  \n",
        "\n",
        "print (datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vjjkR9X08NL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPkP3zRP09AL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"def gradientDescent(X, y, numparams)\")\n",
        "def gradientDescent(X, y, numparams):\n",
        "  # iteratively update parameter vector theta\n",
        "  # -- you should not modify this function\n",
        "\n",
        "  # initialize variables for learning rate and iterations\n",
        "  alpha = 0.02\n",
        "  iters = 5000\n",
        "  cost = np.zeros(iters)\n",
        "  theta= np.zeros(numparams)\n",
        "\n",
        "  for i in range(iters):\n",
        "    theta = theta - alpha * computeGradient(X,y,theta)\n",
        "    cost[i] = computeCost(X, y, theta)\n",
        "\n",
        "  return theta, cost\n",
        "\n",
        "\n",
        "\n",
        "print(\"def normaliseData(x)\")\n",
        "def normaliseData(x):\n",
        "  # rescale data to lie between 0 and 1\n",
        "  scale = x.max(axis=0)\n",
        "  return (x/scale, scale)\n",
        "\n",
        "\n",
        "\n",
        "print(\"def splitData(X, y)\")\n",
        "def splitData(X, y):\n",
        "  # split data into training and test parts\n",
        "  # ... for now, we use all of the data for training and testing\n",
        "  Xtrain=X; ytrain=y; Xtest=X; ytest=y\n",
        "  return (Xtrain, ytrain, Xtest, ytest)\n",
        "\n",
        "\n",
        "print (datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqEOQP5Z0-J-",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "_main_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH7808b81TMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"def main()\")\n",
        "def main():\n",
        "  # load the data\n",
        "  # \"https://raw.githubusercontent.com/johnsl01/Titanic_Python/master/titanic_known.csv\"\n",
        "  data=np.loadtxt('https://raw.githubusercontent.com/johnsl01/linreg/master/stockprices.csv',usecols=(1,2))\n",
        "  X=data[:,0]\n",
        "  y=data[:,1]\n",
        "\n",
        "  # plot the data so we can see how it looks\n",
        "  # (output is in file graph.png)\n",
        "  fig, ax = plt.subplots(figsize=(12, 8))\n",
        "  ax.scatter(X, y, label='Data')\n",
        "  ax.set_xlabel('Amazon')\n",
        "  ax.set_ylabel('Google')\n",
        "  ax.set_title('Google stock price vs Amazon')\n",
        "  fig.savefig('graph.png')\n",
        "\n",
        "  # split the data into training and test parts\n",
        "  (Xtrain, ytrain, Xtest, ytest)=splitData(X,y)\n",
        "\n",
        "  # add a column of ones to input data\n",
        "  m=len(y) # m is number of training data points\n",
        "  Xtrain = np.column_stack((np.ones((m, 1)), Xtrain))\n",
        "  (m,n)=Xtrain.shape # m is number of data points, n number of features\n",
        "\n",
        "  # rescale training data to lie between 0 and 1\n",
        "  (Xt,Xscale) = normaliseData(Xtrain)\n",
        "  (yt,yscale) = normaliseData(ytrain)\n",
        "\n",
        "  # calculate the prediction\n",
        "  print('testing the prediction function ...')\n",
        "  theta=(1,2)\n",
        "  print('when x=[1,1] and theta is [1,2]) cost = ',predict(np.ones(n),theta))\n",
        "  print('approx expected prediction is 3')\n",
        "  print('when x=[[1,1],[5,5]] and theta is [1,2]) cost = ',predict(np.array([[1,1],[5,5]]),theta))\n",
        "  print('approx expected prediction is [3,15]')\n",
        "  input('Press Enter to continue...')\n",
        "\n",
        "  # calculate the cost when theta iz zero\n",
        "  print('testing the cost function ...')\n",
        "  theta=np.zeros(n)\n",
        "  print('when theta is zero cost = ',computeCost(Xt,yt,theta))\n",
        "  print('approx expected cost value is 0.318')\n",
        "  input('Press Enter to continue...')\n",
        "\n",
        "  # calculate the gradient when theta is zero\n",
        "  print('testing the gradient function ...')\n",
        "  print('when theta is zero gradient = ',computeGradient(Xt,yt,theta))\n",
        "  print('approx expected gradient value is [-0.79,-0.59]')\n",
        "  input('Press Enter to continue...')\n",
        "\n",
        "  # perform gradient descent to \"fit\" the model parameters\n",
        "  print('running gradient descent ...')\n",
        "  theta, cost = gradientDescent(Xt, yt, n)\n",
        "  print('after running gradientDescent() theta=',theta)\n",
        "  print('approx expected value is [0.34, 0.61]')\n",
        "\n",
        "  # plot some predictions\n",
        "  Xpred = np.linspace(X.min(), X.max(), 100)\n",
        "  Xpred = np.column_stack((np.ones((100, 1)), Xpred))\n",
        "  ypred = predict(Xpred/Xscale, theta)*yscale\n",
        "  fig, ax = plt.subplots(figsize=(12, 8))\n",
        "  ax.scatter(Xtest, ytest, color='b', label='Test Data')\n",
        "  ax.plot(Xpred[:,1], ypred, 'r', label='Prediction')\n",
        "  ax.set_xlabel('Amazon')\n",
        "  ax.set_ylabel('Google')\n",
        "  ax.legend(loc=2)\n",
        "  fig.savefig('pred.png')\n",
        "\n",
        "  # and plot how the cost varies as the gradient descent proceeds\n",
        "  fig2, ax2 = plt.subplots(figsize=(12, 8))\n",
        "  ax2.semilogy(cost,'r')\n",
        "  ax2.set_xlabel('iteration')\n",
        "  ax2.set_ylabel('cost')\n",
        "  fig2.savefig('cost.png')\n",
        "  \n",
        "  # plot the cost function\n",
        "  fig3 = plt.figure()\n",
        "  ax3 = fig3.add_subplot(1, 1, 1, projection='3d')\n",
        "  n=100\n",
        "  theta0, theta1 = np.meshgrid(np.linspace(-3, 3, n), np.linspace(-3, 2, n))\n",
        "  cost = np.empty((n,n))\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      cost[i,j] = computeCost(Xt,yt,(theta0[i,j],theta1[i,j]))\n",
        "  ax3.plot_surface(theta0,theta1,cost)\n",
        "  ax3.set_xlabel('theta0')\n",
        "  ax3.set_ylabel('theta1')\n",
        "  ax3.set_zlabel('J(theta)')\n",
        "  fig3.savefig('J.png')\n",
        "  \n",
        "# end def main()  \n",
        "  \n",
        "print (datetime.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNsoCBRt1bha",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiLpSKwE1ckc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (datetime.now())\n",
        "\n",
        "main()\n",
        "\n",
        "print (datetime.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpP7InSLDUl4",
        "colab_type": "text"
      },
      "source": [
        "##_ \n",
        "_testing section_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjI-DG_EDV76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test section (predict)\n",
        "# assume all defs are in place \n",
        "# but main hasn't run\n",
        "print(\"Test of multi variable prediction\")\n",
        "print(\"Three variables - five data points - with B0\")\n",
        "test_array = np.array([[1,2,3,5],\n",
        "                       [1,7,11,13],\n",
        "                       [1,17,19,23],\n",
        "                       [1,29,31,37],\n",
        "                       [1,41,43,47]])\n",
        "print (\"shape of test data : \" , test_array.shape )\n",
        "test_theta = np.array([1,2,3,5])\n",
        "print (\"shape of test theta : \", test_theta.shape )\n",
        "\n",
        "test_predict = predict (test_array, test_theta)\n",
        "print(test_predict)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfEqQxWOfZuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Test of multi variable cost\")\n",
        "print (\"cost when theta is all zeros and when theta is correct\")\n",
        "test_array = np.array([[1,2,3,5],\n",
        "                       [1,7,11,13],\n",
        "                       [1,17,19,23],\n",
        "                       [1,29,31,37],\n",
        "                       [1,41,43,47]])\n",
        "print (\"shape of test data : \" , test_array.shape )\n",
        "test_theta = np.array([0,0,0,0])\n",
        "print (\"shape of test theta : \", test_theta.shape )\n",
        "test_results = np.array([22,61,117,191,261])\n",
        "print (\"shape of test results : \", test_results.shape )\n",
        "good_theta = np.array([5,3,2,1])\n",
        "print (\"shape of correct theta : \", good_theta.shape )\n",
        "\n",
        "test_cost =  computeCost(test_array, test_results, test_theta)\n",
        "print (\"cost at theta all zeros : \" , test_cost)\n",
        "\n",
        "good_cost =  computeCost(test_array, test_results, good_theta)\n",
        "print (\"cost at correct theta : \" , good_cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMeRkQNxv3H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Test of Gradient Descent\")\n",
        "print (\"At zero theta and correct theta\")\n",
        "test_array = np.array([[1,2,3,5],\n",
        "                       [1,7,11,13],\n",
        "                       [1,17,19,23],\n",
        "                       [1,29,31,37],\n",
        "                       [1,41,43,47]])\n",
        "print (\"shape of test data : \" , test_array.shape )\n",
        "test_theta = np.array([0,0,0,0])\n",
        "print (\"shape of test theta : \", test_theta.shape )\n",
        "test_results = np.array([22,61,117,191,261])\n",
        "print (\"shape of test results : \", test_results.shape )\n",
        "good_theta = np.array([5,3,2,1])\n",
        "\n",
        "test_grad =  computeGradient(test_array, test_results, test_theta)\n",
        "print (\"gradient at theta all zeros : \" , test_grad)\n",
        "\n",
        "good_grad =  computeGradient(test_array, test_results, good_theta)\n",
        "print (\"gradient at theta correct : \" , good_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oS8R4vJ0xoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# full implementation with multi variable test data \n",
        "X = np.array([[2,3,5],\n",
        "              [7,11,13],\n",
        "              [17,19,23],\n",
        "              [29,31,37],\n",
        "              [41,43,47]])\n",
        "print (\"shape of test data : \" , X.shape )\n",
        "print (\"test data : \\n \", X)\n",
        "\n",
        "# perfectly linear results\n",
        "# y = np.array([22,61,117,191,261])\n",
        "\n",
        "# Or with some some non linearity \n",
        "y = np.array([23,60,118,193,260])\n",
        "\n",
        "print (\"shape of test results : \", y.shape )\n",
        "print (\"results : \" , y )\n",
        "\n",
        "good_theta = np.array([5,3,2,1])\n",
        "\n",
        "# Starting Position \n",
        "# note : without col of 1s in data (they get added below)\n",
        "\n",
        "\n",
        "# split the data into training and test parts\n",
        "#   note : current split is 100% train\n",
        "(Xtrain, ytrain, Xtest, ytest)=splitData(X,y)\n",
        "\n",
        "# add a column of ones to input data\n",
        "m=len(ytrain) # m is number of training data points\n",
        "# note this is a flaw in the original code as it was len(y) which only works if\n",
        "# the train/test split is 100% - so it needs to be len (ytrain) to avoid confusion\n",
        "Xtrain = np.column_stack((np.ones((m)), Xtrain))\n",
        "\n",
        "print (\"Shape of training data : \" , Xtrain.shape)\n",
        "print (\"Training Data : \\n \" , Xtrain)\n",
        " \n",
        "(m,n)=Xtrain.shape # m is number of data points, n number of features\n",
        "\n",
        "# rescale training data to lie between 0 and 1\n",
        "(Xt,Xscale) = normaliseData(Xtrain)\n",
        "(yt,yscale) = normaliseData(ytrain)\n",
        "\n",
        "print (\"Shape of training data : \" , Xt.shape)\n",
        "print (\"Training Data : \\n \" , Xt)\n",
        "\n",
        "# perform gradient descent to \"fit\" the model parameters\n",
        "# print('running gradient descent ...')\n",
        "# theta, cost = gradientDescent(Xt, yt, n)\n",
        "# print('after running gradientDescent() theta=',theta , \"\\n at cost : \" , cost)\n",
        "\n",
        "theta_init = np.zeros(n)\n",
        "iters = 1000000\n",
        "alpha = 0.1\n",
        "\n",
        "initial_cost = computeCost ( Xt, yt, theta_init)\n",
        "print (\"Initial theta : \" , theta_init )\n",
        "print (\"Initial cost = \", initial_cost)\n",
        "\n",
        "\n",
        "print('running gradient descent ...')\n",
        "theta_new, cost = gradDescent(Xt, yt, theta_init, iters, alpha)\n",
        "# print('after running gradientDescent() theta=',theta , \"\\n at cost : \" , cost)\n",
        "\n",
        "final_cost = cost[len(cost)-1]\n",
        "\n",
        "print (\"final theta : \" , theta_new )\n",
        "print (\"final cost = \", final_cost)\n",
        "\n",
        "\n",
        "# and plot how the cost varies as the gradient descent proceeds\n",
        "fig2, ax2 = plt.subplots(figsize=(12, 8))\n",
        "ax2.semilogy(cost,'r')\n",
        "ax2.set_xlabel('iteration')\n",
        "ax2.set_ylabel('cost')\n",
        "# fig2.savefig('cost.png')\n",
        "\n",
        "theta_init = theta_new\n",
        "iters = 5\n",
        "alpha = 0.1\n",
        "\n",
        "initial_cost = computeCost ( Xt, yt, theta_init)\n",
        "print (\"Initial theta : \" , theta_init )\n",
        "print (\"Initial cost = \", initial_cost)\n",
        "\n",
        "\n",
        "print('running gradient descent ...')\n",
        "theta_new, cost = gradDescent(Xt, yt, theta_init, iters, alpha)\n",
        "# print('after running gradientDescent() theta=',theta , \"\\n at cost : \" , cost)\n",
        "\n",
        "final_cost = cost[len(cost)-1]\n",
        "\n",
        "print (\"final theta : \" , theta_new )\n",
        "print (\"final cost = \", final_cost)\n",
        "\n",
        "\n",
        "# and plot how the cost varies as the gradient descent proceeds\n",
        "fig3, ax3 = plt.subplots(figsize=(20, 8))\n",
        "ax3.semilogy(cost,'r')\n",
        "ax3.set_xlabel('iteration')\n",
        "ax3.set_ylabel('cost')\n",
        "# fig2.savefig('cost.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNFAS80nGUHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (test_array, \"\\n\")\n",
        "print (test_array * 2, \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLVjtO73Gekf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (test_array + test_array, \"\\n\")\n",
        "print (test_array[0,:], \"\\n\")\n",
        "print (test_array[1,:], \"\\n\")\n",
        "print (test_array[2,:], \"\\n\")\n",
        "print (test_array[:,0], \"\\n\")\n",
        "print (test_array[:,1], \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOFsB7PkWMgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_1 = np.zeros((test_array.shape[0],test_array.shape[1]))\n",
        "print (predict_1.shape, \"\\n\")\n",
        "print (predict_1, \"\\n\")\n",
        "\n",
        "print (predict_1[0,:], \"\\n\")\n",
        "print (predict_1[1,:], \"\\n\")\n",
        "print (predict_1[2,:], \"\\n\")\n",
        "print (predict_1[:,0], \"\\n\")\n",
        "print (predict_1[:,1], \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7KElaA90mQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testnum = \"Case #1\"\n",
        "myX = np.array([1,1])\n",
        "mytheta = (1,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_2lfFOB9p-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testnum = \"Case #2\"\n",
        "myX = np.array([[1,1],[5,5]])\n",
        "mytheta = (1,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NEBjvfq-Z4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (testnum)\n",
        "print (datetime.now(), \"\\n\")\n",
        "print (\"Shape of myX : \", myX.shape, \"\\n\")\n",
        "print (\"Type of myX.shape : \" , type (myX.shape), \"\\n\")\n",
        "print (\"Len of myX.shape : \", len(myX.shape), \"\\n\")\n",
        "if len(myX.shape) == 1 : \n",
        "  print (\"myX col 0 : \", myX[0], \"\\n\")\n",
        "  print (\"myX col 1 : \", myX[1], \"\\n\")\n",
        "else : \n",
        "  print (\"myX col 0 : \", myX[:,0], \"\\n\")\n",
        "  print (\"myX col 1 : \", myX[:,1], \"\\n\")\n",
        "print (mytheta[0], \"\\n\")\n",
        "print (mytheta[1], \"\\n\", \"\\n\")\n",
        "mypredict_1 = predict(myX,mytheta)\n",
        "print (mypredict_1.shape, \"\\n\")\n",
        "print (mypredict_1, \"\\n\", \"\\n\")\n",
        "print (datetime.now(), \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoHThVczECeX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie7Prpo2EDFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multi dimensional test example\n",
        "# need two dependant variables \n",
        "# will produce a planar regression.\n",
        "# need some data\n",
        "# use the existing amazon and google data \n",
        "# but generate a new result variable\n",
        "# based on an integer multiple of each of the variables \n",
        "# with a randon factor thrown into each plus an additional \n",
        "# randon factor.\n",
        "data=np.loadtxt('https://raw.githubusercontent.com/johnsl01/linreg/master/stockprices.csv',usecols=(1,2))\n",
        "# X=data[:,0]\n",
        "# y=data[:,1]\n",
        "X = data\n",
        "y = X[:,0]*3 \n",
        "y = y + X[:,1]*2\n",
        "print (X.shape, y.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}