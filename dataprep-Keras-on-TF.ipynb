{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataprep-keras-on-tf",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PhJIh3FV7NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Imports\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import sklearn as skl\n",
        "from sklearn import linear_model\n",
        "from sklearn import neural_network as nnet\n",
        "from sklearn import svm\n",
        "from sklearn import ensemble\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "# !pip install category_encoders\n",
        "# import category_encoders as ce\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D as a3d\n",
        "from google.colab import files\n",
        "from datetime import datetime as dt\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO4ToSewZTPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Data loads\")\n",
        "training_path = \"https://raw.githubusercontent.com/johnsl01/income/master/incomeknown.csv\"\n",
        "train_df = pd.read_csv(training_path)\n",
        "test_path = \"https://raw.githubusercontent.com/johnsl01/income/master/incomeunknown.csv\"\n",
        "test_df = pd.read_csv(test_path)\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wj6pVJmy4vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Rename columns to not contain spaces\")\n",
        "\n",
        "newnames = {\"Year of Record\" : \"Year\",\n",
        "           \"Size of City\" : \"CitySize\",\n",
        "           \"University Degree\" : \"Degree\",\n",
        "           \"Wears Glasses\" : \"Glasses\",\n",
        "           \"Hair Color\" : \"Hair\",\n",
        "           \"Body Height [cm]\" : \"Height\",\n",
        "           \"Income in EUR\" : \"Income\"\n",
        "          }\n",
        "\n",
        "train_df.rename(columns=newnames, inplace=True)\n",
        "test_df.rename(columns=newnames, inplace=True)\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRG3CeXgPWsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"hot-one encoding gender\")\n",
        "train_df.Gender.fillna(\"u\", inplace=True) # fillna() replaces Null values\n",
        "test_df.Gender.fillna(\"u\", inplace=True)\n",
        "\n",
        "cols = [\"GenderFemale\", \"GenderMale\", \"GenderOther\", \"GenderUnknown\", \"Gender0\", \"GenderNull\"]\n",
        "genders = [\"female\", \"male\", \"other\", \"unknown\", \"0\", \"u\"]\n",
        "\n",
        "for i in range(len(cols)) : \n",
        "  train_df[cols[i]] = train_df[\"Instance\"]\n",
        "  train_df.loc[train_df.Gender == genders[i], cols[i]] = 1\n",
        "  train_df.loc[train_df.Gender != genders[i], cols[i]] = 0\n",
        "  \n",
        "  test_df[cols[i]] = test_df[\"Instance\"]\n",
        "  test_df.loc[test_df.Gender == genders[i], cols[i]] = 1\n",
        "  test_df.loc[test_df.Gender != genders[i], cols[i]] = 0\n",
        "#end for\n",
        "\n",
        "#print(test_df[\"GenderNull\"].describe())\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8kFla6TXPGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"hot-one encoding hair colour\")\n",
        "train_df.Hair.fillna(\"U\", inplace=True)\n",
        "test_df.Hair.fillna(\"U\", inplace=True)\n",
        "\n",
        "cols = [\"HairBlack\", \"HairBrown\", \"HairRed\", \"HairBlonde\", \"HairUnknown\", \"Hair0\", \"HairNull\"]\n",
        "colours = [\"Black\", \"Brown\", \"Red\", \"Blonde\", \"Unknown\", \"0\", \"U\"]\n",
        "\n",
        "for i in range(len(cols)) :\n",
        "  train_df[cols[i]] = train_df[\"Instance\"]\n",
        "  train_df.loc[train_df.Hair == colours[i], cols[i]] = 1\n",
        "  train_df.loc[train_df.Hair != colours[i], cols[i]] = 0\n",
        "  \n",
        "  test_df[cols[i]] = test_df[\"Instance\"]\n",
        "  test_df.loc[test_df.Hair == colours[i], cols[i]] = 1\n",
        "  test_df.loc[test_df.Hair != colours[i], cols[i]] = 0\n",
        "#end for\n",
        "\n",
        "#print(train_df[\"HairBlack\"].describe())\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtoMGjig7qoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"renaming Profession values\")\n",
        "train_df.Profession.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "test_df.Profession.fillna(\"Unknown\", inplace=True)\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9pMlwUU53b8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"categorically encoding degree values\")\n",
        "\n",
        "train_df.Degree.replace(\"PhD\", 5, inplace=True)\n",
        "train_df.Degree.replace(\"Master\", 4, inplace=True)\n",
        "train_df.Degree.replace(\"Bachelor\", 3, inplace=True)\n",
        "train_df.Degree.replace(\"No\", 2, inplace=True)\n",
        "train_df.Degree.replace(\"0\", 6, inplace=True)\n",
        "train_df.Degree.fillna(1, inplace=True)\n",
        "\n",
        "test_df.Degree.replace(\"PhD\", 5, inplace=True)\n",
        "test_df.Degree.replace(\"Master\", 4, inplace=True)\n",
        "test_df.Degree.replace(\"Bachelor\", 3, inplace=True)\n",
        "test_df.Degree.replace(\"No\", 2, inplace=True)\n",
        "test_df.Degree.replace(\"0\", 6, inplace=True)\n",
        "test_df.Degree.fillna(1, inplace=True)\n",
        "\n",
        "# new Degree values\n",
        "# 4 (was PhD), 3 (was Master), 2 (was Bachelor), 1 (was 0,Null), 0 (was No)\n",
        "\n",
        "print(dt.now())\n",
        "\n",
        "print (\"Validate this - is there a correlation and is it linear - one-hot may be better\")\n",
        "print (\"  or consider encoding the nulls as a separate feature 0/1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJPrzU4Xvb5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for degre in [1, 2, 3, 4, 5, 6] :\n",
        "  \n",
        "  print (degre, round(train_df.loc[(train_df.Degree == degre)].Income.median(),0), round(train_df.loc[(train_df.Degree == degre)].Income.mean(),0), round(train_df.loc[(train_df.Degree == degre)].Income.std(),0) )\n",
        "  \n",
        "print(dt.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTioyE51xAVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "for degre in [0, 1, 2, 3, 4, 5] :\n",
        "  \n",
        "  print (degre, train_df.loc[(train_df.Degree == degre)].Income.median(), train_df.loc[(train_df.Degree == degre)].Income.median())\n",
        "  \n",
        "print(dt.now())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE9-5Q4X-lIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"replacing Null ages and years with median\")\n",
        "# median age\n",
        "train_med_age = train_df[\"Age\"].median()\n",
        "print(\"train median age = \", train_med_age)\n",
        "test_med_age = test_df[\"Age\"].median()\n",
        "print(\"test median age = \", test_med_age)\n",
        "mean_of_age_medians = (train_med_age + test_med_age)/2\n",
        "print(\"mean = \", mean_of_age_medians)\n",
        "\n",
        "print(\"replacing age...\")\n",
        "train_df.Age.fillna(mean_of_age_medians, inplace=True)\n",
        "test_df.Age.fillna(mean_of_age_medians, inplace=True)\n",
        "\n",
        "# median year\n",
        "train_med_yr = train_df[\"Year\"].median()\n",
        "print(\"train median year = \", train_med_yr)\n",
        "test_med_yr = test_df[\"Year\"].median()\n",
        "print(\"test median year = \", test_med_yr)\n",
        "mean_of_yr_medians = (train_med_yr + test_med_yr)/2\n",
        "print(\"mean = \", mean_of_yr_medians)\n",
        "\n",
        "print(\"replacing year...\")\n",
        "train_df.Year.fillna(mean_of_yr_medians, inplace=True)\n",
        "test_df.Year.fillna(mean_of_yr_medians, inplace=True)\n",
        "\n",
        "print(dt.now())\n",
        "\n",
        "print (\"Again - validate these two - may be a better choice - MICE etc.\")\n",
        "print (\"   Is there a correlation - explore this more\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJkRXjSFBMpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "print(\"Capping city size at 2mil\")\n",
        "# only 19 people live in cities above 2mil in train_df\n",
        "\n",
        "twomil = 2000000\n",
        "train_df[\"CitySize\"].values[train_df[\"CitySize\"] > twomil] = twomil\n",
        "test_df[\"CitySize\"].values[test_df[\"CitySize\"] > twomil] = twomil\n",
        "\n",
        "print(dt.now())\n",
        "\n",
        "print (\"Is there any relevant correlation here - capping result may makes sense\")\n",
        "print (\"but is there any point in capping an independent variable ?\")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF9FB6lfBTpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Adding column that labels instances where citysize<=100k\")\n",
        "\n",
        "hunk = 100000\n",
        "train_df[\"LivesInTown\"] = train_df[\"Instance\"]\n",
        "train_df[\"LivesInTown\"].values[train_df[\"CitySize\"] <= hunk] = 1\n",
        "train_df[\"LivesInTown\"].values[train_df[\"CitySize\"] > hunk] = 0\n",
        "\n",
        "\n",
        "test_df[\"LivesInTown\"] = test_df[\"Instance\"]\n",
        "test_df[\"LivesInTown\"].values[test_df[\"CitySize\"] <= hunk] = 1\n",
        "test_df[\"LivesInTown\"].values[test_df[\"CitySize\"] > hunk] = 0\n",
        "\n",
        "print(dt.now())\n",
        "\n",
        "print(\"There is an identified corelation here\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0i2izty9Y5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"encoding country data\")\n",
        "\n",
        "overall_md = train_df[\"Income\"].median()\n",
        "overall_mean = train_df[\"Income\"].mean()\n",
        "\n",
        "# if not particularly acurate, try using country_count too,\n",
        "# since smaller sample sizes seem to have much higher wages\n",
        "\n",
        "# add new column that holds the difference between\n",
        "# the mean income for a country and the mean overall\n",
        "# countries in Test that are not in Train will be left as 0\n",
        "# (ie. mean overall for train)\n",
        "train_df[\"CountryMed\"] = train_df[\"Instance\"]\n",
        "train_df = train_df.assign(CountryMed = 0)\n",
        "train_df[\"CountryMean\"] = train_df[\"Instance\"]\n",
        "train_df = train_df.assign(CountryMean = 0)\n",
        "\n",
        "test_df[\"CountryMed\"] = train_df[\"Instance\"]\n",
        "test_df = test_df. assign(CountryMed = 0)\n",
        "test_df[\"CountryMean\"] = train_df[\"Instance\"]\n",
        "test_df = test_df. assign(CountryMean = 0)\n",
        "\n",
        "for cntry in train_df.Country.unique():\n",
        "  # count = len(train_df.loc[(train_df.Country == cntry)])\n",
        "  country_md = train_df.loc[(train_df.Country == cntry)].Income.median()\n",
        "  country_mean = train_df.loc[(train_df.Country == cntry)].Income.mean()\n",
        "  median_diff = country_md - overall_md\n",
        "  mean_diff = country_mean - overall_mean\n",
        "  # replacing CountryMean (was 0)\n",
        "  train_df.loc[(train_df.Country == cntry), \"CountryMed\"] = median_diff\n",
        "  train_df.loc[(train_df.Country == cntry), \"CountryMean\"] = mean_diff\n",
        "  test_df.loc[(test_df.Country == cntry), \"CountryMed\"] = median_diff\n",
        "  test_df.loc[(test_df.Country == cntry), \"CountryMean\"] = mean_diff\n",
        "  # end for\n",
        "#end for\n",
        "print(dt.now())\n",
        "\n",
        "# there is an identified corelation between countries with fewer sample and \n",
        "# income.\n",
        "\n",
        "# perhaps add a sample count col - and this could be the sample count from the \n",
        "# whole data set as this is likely the way it was introduced - but small sample\n",
        "# sizes may be therefore inaccurate in test if under or over \n",
        "# represeneted and result in over fitting. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odCXl-tYRRng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"encoding profession data\")\n",
        "\n",
        "overall_md = train_df[\"Income\"].median()\n",
        "overall_mean = train_df[\"Income\"].mean()\n",
        "\n",
        "# if not particularly acurate, try using prof_count too?\n",
        "\n",
        "# add new column that holds the difference between\n",
        "# the mean income for a country and the mean overall\n",
        "# countries in Test that are not in Train will be left as 0\n",
        "# (ie. mean overall for train)\n",
        "train_df[\"ProfMed\"] = train_df[\"Instance\"]\n",
        "train_df = train_df.assign(ProfMed = 0)\n",
        "train_df[\"ProfMean\"] = train_df[\"Instance\"]\n",
        "train_df = train_df.assign(ProfMean = 0)\n",
        "\n",
        "test_df[\"ProfMed\"] = train_df[\"Instance\"]\n",
        "test_df = test_df. assign(ProfMed = 0)\n",
        "test_df[\"ProfMean\"] = train_df[\"Instance\"]\n",
        "test_df = test_df. assign(ProfMean = 0)\n",
        "\n",
        "for prof in train_df.Profession.unique():\n",
        "  # count = len(train_df.loc[(train_df.Profession == prof)])\n",
        "  prof_md = train_df.loc[(train_df.Profession == prof)].Income.median()\n",
        "  prof_mean = train_df.loc[(train_df.Profession == prof)].Income.mean()\n",
        "  mean_diff = prof_mean - overall_mean\n",
        "  median_diff = prof_md - overall_md\n",
        "  # replacing CountryMean (was 0)\n",
        "  train_df.loc[(train_df.Profession == prof), \"ProfMed\"] = median_diff\n",
        "  train_df.loc[(train_df.Profession == prof), \"ProfMean\"] = mean_diff\n",
        "  test_df.loc[(test_df.Profession == prof), \"ProfMed\"] = median_diff\n",
        "  test_df.loc[(test_df.Profession == prof), \"ProfMean\"] = mean_diff\n",
        "  # end for\n",
        "#end for\n",
        "print(dt.now())\n",
        "\n",
        "# need to check this correlation - ther3e may be a more obvious link\n",
        "# the high counts in the 'p', 'r', 's' etc professions \n",
        "# and low counts in 'a', 'b'. 'c' suggest artifical data."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyizzIIjKyfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"normalise data\")\n",
        "# merge tables in order to normalise properly\n",
        "(split_point, _) = train_df.shape\n",
        "all_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "#print(all_df.describe())\n",
        "\n",
        "# selects columns to normalise and normalises\n",
        "all_num = all_df[\n",
        "    [\"Year\", \"Age\", \"CountryMed\", \n",
        "     \"CountryMean\", \"ProfMed\", \"ProfMean\", \n",
        "     \"CitySize\", \"Degree\", \"Height\"]]\n",
        "all_norm = (all_num - all_num.min())/ (all_num.max()-all_num.min())\n",
        "\n",
        "#print(all_norm.describe())\n",
        "\n",
        "# (rows, _) = all_norm.shape\n",
        "# tmp = np.ones(rows)\n",
        "# all_norm.insert(0, \"Ones\", tmp)\n",
        "\n",
        "# add all data that's already binary data\n",
        "all_norm[\"Glasses\"] = all_df[\"Glasses\"]\n",
        "all_norm[\"LivesInTown\"] = all_df[\"LivesInTown\"]\n",
        "all_norm[\"GenderMale\"] = all_df[\"GenderMale\"]\n",
        "all_norm[\"GenderFemale\"] = all_df[\"GenderFemale\"]\n",
        "all_norm[\"GenderUnknown\"] = all_df[\"GenderUnknown\"]\n",
        "all_norm[\"Gender0\"] = all_df[\"Gender0\"]\n",
        "all_norm[\"GenderNull\"] = all_df[\"GenderNull\"]\n",
        "all_norm[\"HairBlack\"] = all_df[\"HairBlack\"]\n",
        "all_norm[\"HairBrown\"] = all_df[\"HairBrown\"]\n",
        "all_norm[\"HairBlonde\"] = all_df[\"HairBlonde\"]\n",
        "all_norm[\"HairRed\"] = all_df[\"HairRed\"]\n",
        "all_norm[\"HairUnknown\"] = all_df[\"HairUnknown\"]\n",
        "all_norm[\"Hair0\"] = all_df[\"Hair0\"]\n",
        "all_norm[\"HairNull\"] = all_df[\"HairNull\"]\n",
        "\n",
        "# split data\n",
        "train_norm = all_norm.head(split_point)\n",
        "test_norm = all_norm.tail(len(all_norm) - split_point)\n",
        "#print(train_norm.describe())\n",
        "#print(test_norm.describe())\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKlQOJmJknHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
        "\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
        "\n",
        "#   25    : 0.2497450605388929 - 0.25324189201654834 -       11 secs\n",
        "#   50    : 0.6616425189653192 - 0.73051652138610000\n",
        "#  100    : 0.7827040270315250 - 0.78551363329530390 -     1:04\n",
        "#  200    : 0.8195381668117979 -                           4:04\n",
        "\n",
        "# learning from previous - makes timing difficult - and isn't that effective\n",
        "# and early stopping excludes data so this is not helpful in this case\n",
        "# warm_start=False, early_stopping=False,\n",
        "#   25    : 0.28669907374694426 - 0.3143078977278916 -       11\n",
        "#   50    : 0.73137165225086110 - 0.7229390424910851 -       31          36\n",
        "#  100    : 0.78481393684434940 - 0.7857755827423643 -     1:06        1:11\n",
        "#  200    : 0.7903792664668625 -                           4:27\n",
        "#  500    : 0.8450908332162614 -                          14:06\n",
        "\n",
        "# default layers make no sense try (20,10)\n",
        "# hidden_layer_sizes=(20,10),\n",
        "# first hidden layer matched to inputs - and use a second as the data has arbitrary\n",
        "# thresholds\n",
        "# (number of features is a good number of neurons per layer - deeper gives more sophistication)\n",
        "#    25   : 0.7887734639019761 - 0.7809109537904840 -         06          06\n",
        "\n",
        "#   100   : 0.7947890140674736 - 0.7922373078596026 -       0:46        0:33\n",
        "\n",
        "#   500   : 0.8675915246886190 -                            4:44\n",
        "\n",
        "#  2500   : 0.7923683126864547 - 0.8622292552558385         0:39 ?      8:34\n",
        " \n",
        "# hidden_layer_sizes=(20,10,4),\n",
        "# early_stopping=True,  \n",
        "\n",
        "#    25   : 0.8329299620790784 - 0.7815451498511101         0:07        0:07\n",
        " \n",
        "#   100   : \n",
        "\n",
        "# try verbose=True on a small example\n",
        "\n",
        "\n",
        "# hidden_layer_sizes=(20,10,5),\n",
        "# learning_rate_init=0.001,\n",
        "# early_stopping=True,\n",
        "\n",
        "#    25   : 0.19057347109521827  0:07\n",
        "\n",
        "#   100   : 0.78176263624963760  0:33  \n",
        "\n",
        "#   500   : 0.85071602031931740  5:39\n",
        "\n",
        "#  2500   : 0.85154263342489110  2:29 276\n",
        "\n",
        "\n",
        "# hidden_layer_sizes=(20,20),\n",
        "\n",
        "#  2500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhZhFB9-VCaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# add some more loops \n",
        "# and complete investigation of data = ref above\n",
        "\n",
        "\n",
        "# for hidden in [(5,), (10,), (20,), (30,), (10,5), (10,10), (15,10), (20, 10), (20,20), (15,10,5), (20,10,5), (20,20,10), (20,20,20), (30,20,20), (30,20,10,5), (40,30,20,10)] :\n",
        "for dpth in [2,3,4,5,6,7,8,9,10] :\n",
        "  for iters in [200, 500, 1000] :\n",
        "    print (\"\\n    \",dpth,iters)\n",
        "    # print (\"\\n    \",hidden,iters)\n",
        "    print(\"      Fitting model and checking score on Known data\" , iters, \"iterations\")\n",
        "    Known = train_norm.copy()\n",
        "    y = train_df[\"Income\"].copy()\n",
        "\n",
        "\n",
        "    #mod = linear_model.BayesianRidge(copy_X=False, tol=0.00001, n_iter=1000)\n",
        "    # 0.7349053641228902\n",
        "        \n",
        "    # mod = nnet.MLPRegressor(\n",
        "    #     hidden_layer_sizes= hidden,\n",
        "    #     tol=0.00001, n_iter_no_change=25,\n",
        "    #     warm_start=False, early_stopping=True,\n",
        "    #     learning_rate=\"adaptive\", learning_rate_init=0.001,\n",
        "    #     max_iter=iters)\n",
        "        \n",
        "    # mod = ensemble.AdaBoostRegressor( n_estimators=100 )\n",
        "    # doesn't work   \n",
        "    \n",
        "    # mod = svm.LinearSVR( tol=1e-5, max_iter =10000)\n",
        "    # doesn't work\n",
        "    \n",
        "    # mod = ensemble.RandomForestRegressor(max_depth=7, n_estimators=1000)\n",
        "    # 0.8288730954198963 in 6:06 - (max_depth=7, n_estimators=1000)\n",
        "    mod = ensemble.RandomForestRegressor(max_depth=dpth, n_estimators=(iters*2))\n",
        "    \n",
        "    \n",
        "    dtstart = dt.now()\n",
        "    print(\"      model created \", dt.now())\n",
        "    mod.fit(Known, y)\n",
        "    print(\"      model   fit   \", dt.now())\n",
        "\n",
        "    print(\"      \", mod.score(Known, y))\n",
        "\n",
        "    print (\"      \", dt.now() - dtstart)\n",
        "    # print (\"      \", mod.n_iter_)\n",
        "\n",
        "    # print(\"      \", dt.now())\n",
        "  \n",
        "  # end for\n",
        "  print('end   ', hidden, dt.now())\n",
        "# end for\n",
        "print('end', iters, dt.now())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMrpWBfDC6mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# new section to use test/train split validation  \n",
        "# to find the model complexity at which overfitting begins to occur.\n",
        "\n",
        "# We also need to understand how this overfitting point moves with dataset size\n",
        "# as the full model (i.e trained on all the data) which we eventually produce\n",
        "# may need to be slightly more complex,\n",
        "# so we look for the overfitting point on two different sizes of test data.\n",
        "\n",
        "# the models we are working with have multiple parameters which govern their \n",
        "# behaviour - so there is a gradual approach towards the overfitting point \n",
        "\n",
        "# in general with the number of samples several orders of magnitiude larger\n",
        "# than the number of features we have to push the models pretty hard to get to \n",
        "# an overfit\n",
        "\n",
        "# initialise results vectors\n",
        "\n",
        "train1R2 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "train2R2 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "train3R2 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "test1R2 =  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "test2R2 =  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "# pull in our full Known data (already engineered and normalised)\n",
        "# and our full known result\n",
        "\n",
        "# df = train_norm.copy()\n",
        "# y = train_df[\"Income\"].copy()\n",
        "\n",
        "# X_train1, X_test1, y_train1, y_test1 = train_test_split(df, y, test_size=0.5)\n",
        "\n",
        "# X_train2, X_test2, y_train2, y_test2 = train_test_split(df, y, test_size=0.2)\n",
        "\n",
        "# run 10 samples ( modify parameters to suit needs)\n",
        "# for i in [8,9] :\n",
        "for i in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19] :\n",
        "  \n",
        "  df = train_norm.copy()\n",
        "  y = train_df[\"Income\"].copy()\n",
        "\n",
        "  X_train1, X_test1, y_train1, y_test1 = train_test_split(df, y, test_size=0.5)\n",
        "\n",
        "  X_train2, X_test2, y_train2, y_test2 = train_test_split(df, y, test_size=0.2)\n",
        "  \n",
        "  X_train3 = df\n",
        "  y_train3 = y\n",
        "  \n",
        "  # Random Forrest : \n",
        "  dpth = [2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11]\n",
        "  tres = [500, 1000, 500, 1000, 500, 1000, 500, 1000, 500, 1000, 500, 1000, 500, 1000, 500, 1000, 500, 1000, 500, 1000]\n",
        "  print(i,\"   model fit   \", dept[i], ' deep ', tres[i], ' trees, ', dt.now())\n",
        "  \n",
        "  dtstart = dt.now()\n",
        "  mod1 = ensemble.RandomForestRegressor(max_depth=dpth[i], n_estimators=tres[i])\n",
        "  mod1.fit(X_train1, y_train1)\n",
        "  train1R2[i] = mod1.score(X_train1, y_train1)\n",
        "  test1R2[i] = mod1.score(X_test1, y_test1)\n",
        "  print ('     Train-1 ', train1R2[i], '    Test-1 ',test1R2[i]  )\n",
        "  \n",
        "  print(\"     \", dt.now() - dtstart)\n",
        "  dtstart = dt.now()\n",
        "  \n",
        "  mod2 = ensemble.RandomForestRegressor(max_depth=dpth[i], n_estimators=tres[i])\n",
        "  mod2.fit(X_train2, y_train2)\n",
        "  train2R2[i] = mod2.score(X_train2, y_train2)\n",
        "  test2R2[i] = mod2.score(X_test2, y_test2)\n",
        "  print ('     Train-2 ', train2R2[i], '    Test-2 ',test2R2[i]  )\n",
        "  \n",
        "  print(\"     \", dt.now() - dtstart)\n",
        "  dtstart = dt.now()\n",
        "  \n",
        "  mod3 = ensemble.RandomForestRegressor(max_depth=dpth[i], n_estimators=tres[i])\n",
        "  mod3.fit(X_train3, y_train3)\n",
        "  train3R2[i] = mod3.score(X_train3, y_train3)\n",
        "  # test2R2[i] = mod2.score(X_test2, y_test2)\n",
        "  print ('     Train-3 ', train3R2[i]  )\n",
        "  \n",
        "  print(\"     \", dt.now() - dtstart)\n",
        "  \n",
        "print ( \" END \")  \n",
        "  \n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk0-uIXdqNCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generalised test model complexity section\n",
        "\n",
        "# model type neural network so\n",
        "# instance is ( max_iterations:int, hidden_layer_config:tupple) : tupple\n",
        "'''\n",
        "testrange=[\n",
        "             (300,  (10,)            )\n",
        "           , (300,  (15,)            )\n",
        "           , (500,  (15,)            )\n",
        "           , (500,  (20,)            )\n",
        "           , (500,  (30,)            )\n",
        "           , (500,  (10,5)           )\n",
        "           , (500,  (10,10)          )\n",
        "           , (500,  (15,10)          )\n",
        "           , (1000, (15,10)          )\n",
        "           , (1000, (20,10)          )\n",
        "           , (1000, (20,20)          )\n",
        "           , (1000, (15,10,5)        )\n",
        "           , (1000, (20,10,5)        )\n",
        "           , (1000, (20,20,10)       )\n",
        "           , (1000, (20,20,20)       )\n",
        "           , (2000, (20,20,20)       )\n",
        "           , (2000, (30,20,20)       )\n",
        "           , (2000, (30,20,10,5)     )\n",
        "           , (2000, (40,30,20,10)    )\n",
        "           , (2000, (40,30,20,10,5)  )\n",
        "           , (5000, (40,30,20,10,5)  )\n",
        "           , (5000, (50,40,30,20,10) )\n",
        "           , (5000, (50,50,40,40,30) )\n",
        "           , (5000, (50,50,50,50,50) )\n",
        "            ]\n",
        "'''\n",
        "testrange=[\n",
        "             (750,  (50,50,50,50,50)       )\n",
        "           , (600,  (60,60,60,60,60,60)    )\n",
        "           , (500,  (70,70,70,70,70,70,70) )\n",
        "          ]\n",
        "\n",
        "testlen = len(testrange)\n",
        "print (testlen, 'test cases')  \n",
        "\n",
        "train1R2 = np.zeros(testlen)\n",
        "train2R2 = np.zeros(testlen)\n",
        "train3R2 = np.zeros(testlen)\n",
        "test1R2 =  np.zeros(testlen)\n",
        "test2R2 =  np.zeros(testlen)\n",
        "    \n",
        "for i in range(testlen) :\n",
        "  \n",
        "  # pick up my model data\n",
        "  model = testrange[i]\n",
        "  iters = model[0]\n",
        "  hidden = model[1]\n",
        "  \n",
        "  print (i, \"Iterations : \", iters, \" hidden layer config : \", hidden )\n",
        "  \n",
        "  # pick up my sample data\n",
        "  # resetting data for each model\n",
        "  df = train_norm.copy()\n",
        "  y = train_df[\"Income\"].copy()\n",
        "\n",
        "  X_train1, X_test1, y_train1, y_test1 = train_test_split(df, y, test_size=0.5)\n",
        "\n",
        "  X_train2, X_test2, y_train2, y_test2 = train_test_split(df, y, test_size=0.2)\n",
        "  \n",
        "  X_train3 = df\n",
        "  y_train3 = y\n",
        "  \n",
        "  # need three identical models\n",
        "  mod1 = nnet.MLPRegressor(\n",
        "                            hidden_layer_sizes= hidden\n",
        "                          , max_iter=iters\n",
        "                          , tol=0.00001\n",
        "                          , n_iter_no_change=25\n",
        "                          , warm_start=False\n",
        "                          , early_stopping=True\n",
        "                          , learning_rate=\"adaptive\"\n",
        "                          , learning_rate_init=0.0001\n",
        "                          )  \n",
        "\n",
        "  mod2 = nnet.MLPRegressor(\n",
        "                            hidden_layer_sizes= hidden\n",
        "                          , max_iter=iters\n",
        "                          , tol=0.00001\n",
        "                          , n_iter_no_change=25\n",
        "                          , warm_start=False\n",
        "                          , early_stopping=True\n",
        "                          , learning_rate=\"adaptive\"\n",
        "                          , learning_rate_init=0.0001\n",
        "                          )\n",
        "  mod = nnet.MLPRegressor(\n",
        "                            hidden_layer_sizes= hidden\n",
        "                          , max_iter=iters\n",
        "                          , tol=0.00001\n",
        "                          , n_iter_no_change=25\n",
        "                          , warm_start=False\n",
        "                          , early_stopping=True\n",
        "                          , learning_rate=\"adaptive\"\n",
        "                          , learning_rate_init=0.0001\n",
        "                          )\n",
        "  \n",
        "  dtstart = dt.now()\n",
        "  \n",
        "  mod1.fit(X_train1, y_train1)\n",
        "  train1R2[i] = mod1.score(X_train1, y_train1)\n",
        "  test1R2[i]  = mod1.score(X_test1, y_test1)\n",
        "  train1RMS = sqrt ( mean_squared_error(y_train1, mod1.predict(X_train1)))\n",
        "  test1RMS  = sqrt ( mean_squared_error(y_test1, mod1.predict(X_test1)))\n",
        "  print ('      Train-1 ', train1R2[i], '     Test-1 ',test1R2[i]  )\n",
        "  print (' RMSE-Train-1 ', train1RMS,   'RMSE-Test-1 ',test1RMS )\n",
        "  print (mod1.n_iter_)\n",
        "  print(\"     \", dt.now() - dtstart)\n",
        "  \n",
        "  dtstart = dt.now()\n",
        "  \n",
        "  mod2.fit(X_train2, y_train2)\n",
        "  train2R2[i] = mod2.score(X_train2, y_train2)\n",
        "  test2R2[i]  = mod2.score(X_test2, y_test2)\n",
        "  train2RMS = sqrt ( mean_squared_error(y_train2, mod2.predict(X_train2)))\n",
        "  test2RMS  =  sqrt ( mean_squared_error(y_test2, mod2.predict(X_test2)))\n",
        "  print ('      Train-2 ', train2R2[i], '     Test-2 ',test2R2[i]  )\n",
        "  print (' RMSE-Train-2 ', train2RMS,   'RMSE-Test-2 ',test2RMS )\n",
        "  print (mod2.n_iter_)\n",
        "  print(\"     \", dt.now() - dtstart)\n",
        "  dtstart = dt.now()\n",
        "  \n",
        "  mod.fit(X_train3, y_train3)\n",
        "  train3R2[i] = mod.score(X_train3, y_train3)\n",
        "  train3RMS = sqrt ( mean_squared_error(y_train3, mod.predict(X_train3)))\n",
        "  # test3R2[i] = mod.score(X_test2, y_test2)\n",
        "  print ('      Train-3 ', train3R2[i]  )\n",
        "  print (' RMSE-Train-3 ', train3RMS )\n",
        "  print (mod.n_iter_)\n",
        "  print(\"     \", dt.now() - dtstart)\n",
        "  \n",
        "  \n",
        "print ( \" END \")\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkpFYOVlkWsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the fitting data\n",
        "\n",
        "tr1 = np.zeros(testlen)\n",
        "tr2 = np.zeros(testlen)\n",
        "tr3 = np.zeros(testlen)\n",
        "ts1 = np.zeros(testlen)\n",
        "ts2 = np.zeros(testlen)\n",
        "\n",
        "x = range(testlen)\n",
        "\n",
        "for i in x : \n",
        "  tr1[i] = 1-train1R2[i]\n",
        "  tr2[i] = 1-train2R2[i]\n",
        "  tr3[i] = 1-train3R2[i] \n",
        "  ts1[i] = 1-test1R2[i]\n",
        "  ts2[i] = 1-test2R2[i]\n",
        "  \n",
        "plt.figure(figsize=(16,8), dpi=80)  \n",
        "plt.plot (x, tr1, color='cyan',  label=\"train 1 -  50%\")\n",
        "plt.plot (x, tr2, color='pink',  label=\"train 2 -  80%\")\n",
        "plt.plot (x, tr3, color='green', label=\"train 3 - 100%\")\n",
        "plt.plot (x, ts1, color='blue',  label=\"test 1 - 50%\")\n",
        "plt.plot (x, ts2, color='red',   label=\"test 2 - 80%\")\n",
        "plt.legend();\n",
        "plt.title(\"Looking for overfitting point\")\n",
        "plt.xlabel(\"model complexity \\n adding iterations and hidden layers\")\n",
        "plt.ylabel(\"1-R2\")\n",
        "\n",
        "# plt.savefig('nn-fit-a.pdf')\n",
        "\n",
        "# files.download('nn-fit-a.pdf')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zczXPG0kdRtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "print (mod.n_iter_)\n",
        "# Known.describe()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ut3w09s0aNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"Predicting unknown data\")\n",
        "Unknown = test_norm.copy()\n",
        "u_income = mod.predict(Unknown)\n",
        "u_mean = u_income.mean()\n",
        "u_std = u_income.std()\n",
        "k_mean = train_df.Income.mean()\n",
        "k_std = train_df.Income.std()\n",
        "print(\"MEAN: k=\", k_mean, \"\\n      u=\",u_mean)\n",
        "print(\"STDD: k=\", k_std, \"\\n      u=\", u_std)\n",
        "print(dt.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVqL6QmCyGvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "submission = pd.DataFrame(columns=[\"Instance\", \"Income\"])\n",
        "submission[\"Instance\"] = test_df[\"Instance\"].copy()\n",
        "submission[\"Income\"] = u_income.copy()\n",
        "submission.to_csv(r\"submission.csv\",index=None, header=True)\n",
        "files.download(\"submission.csv\")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgZjMeQMkR2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77cg9cq0vpr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XPwMPPfLEx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# looking at mean/median for different countries\n",
        "c = \"Solomon Islands\"\n",
        "ggg = train_df.loc[(train_df.Country == c)].Income.mean()\n",
        "print(ggg)\n",
        "hhh = train_df.loc[(train_df.Country == c)].Income.median()\n",
        "print(hhh)\n",
        "print(train_df.Income.mean())\n",
        "print(train_df.Income.median())\n",
        "print(train_df.loc[(train_df.Country == c)].Income)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk1C4EPm_BRr",
        "colab_type": "text"
      },
      "source": [
        "#### https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
        "\n",
        "#### https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
        "\n",
        "   25    : 0.2497450605388929 - 0.25324189201654834 -       11 secs\n",
        "\n",
        "   50    : 0.6616425189653192 - 0.73051652138610000\n",
        "\n",
        "  100    : 0.7827040270315250 - 0.78551363329530390 -     1:04\n",
        "\n",
        "  200    : 0.8195381668117979 -                           4:04\n",
        "\n",
        "#### learning from previous - makes timing difficult - and isn't that effective\n",
        "#### and early stopping excludes data so this is not helpful in this case\n",
        "#### warm_start=False, early_stopping=False,\n",
        "\n",
        "25    : 0.28669907374694426 - 0.3143078977278916 -       11\n",
        "\n",
        "50    : 0.73137165225086110 - 0.7229390424910851 -       31          36\n",
        "\n",
        "100    : 0.78481393684434940 - 0.7857755827423643 -     1:06        1:11\n",
        "\n",
        "200    : 0.7903792664668625 -                           4:27\n",
        "\n",
        "500    : 0.8450908332162614 -                          14:06\n",
        "\n",
        "#### default layers make no sense try (20,10)\n",
        "#### hidden_layer_sizes=(20,10),\n",
        "#### first hidden layer matched to inputs - and use a second as the data has arbitrary\n",
        "#### thresholds\n",
        "#### (number of features is a good number of neurons per layer - deeper gives more sophistication)\n",
        "    25   : 0.7887734639019761 - 0.7809109537904840 -         06          06\n",
        "\n",
        "   100   : 0.7947890140674736 - 0.7922373078596026 -       0:46        0:33\n",
        "\n",
        "   500   : 0.8675915246886190 -                            4:44\n",
        "\n",
        "  2500   : 0.7923683126864547 - 0.8622292552558385         0:39 ?      8:34\n",
        " \n",
        "#### hidden_layer_sizes=(20,10,4),\n",
        "#### early_stopping=True,  \n",
        "\n",
        "    25   : 0.8329299620790784 - 0.7815451498511101         0:07        0:07\n",
        " \n",
        "   100   : \n",
        "\n",
        "#### try verbose=True on a small example\n",
        "\n",
        "\n",
        "#### hidden_layer_sizes=(20,10,5),\n",
        "#### learning_rate_init=0.001,\n",
        "#### early_stopping=True,\n",
        "\n",
        "    25   : 0.19057347109521827  0:07\n",
        "\n",
        "   100   : 0.78176263624963760  0:33  \n",
        "\n",
        "   500   : 0.85071602031931740  5:39\n",
        "\n",
        "  2500   : 0.85154263342489110  2:29 276\n",
        "\n",
        "\n",
        "#### hidden_layer_sizes=(20,20),\n",
        "\n",
        "  2500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvo2ui-sOqer",
        "colab_type": "text"
      },
      "source": [
        "#### add some more loops \n",
        "#### and complete investigation of data = ref above\n",
        "\n",
        "for iters in [25, 100, 500] :\n",
        "  for hidden in [(10,10), (15,10), (20, 10), (20,20), (20,10,5), (20,20,10)] :\n",
        "    print (\"\\n    \",hidden,iters)\n",
        "    print(\"      Fitting model and checking score on Known data\" , iters, \"iterations\")\n",
        "    Known = train_norm.copy()\n",
        "    y = train_df[\"Income\"].copy()\n",
        "\n",
        "\n",
        "    #mod = linear_model.BayesianRidge(copy_X=False, n_iter=1000)\n",
        "    mod = nnet.MLPRegressor(\n",
        "        hidden_layer_sizes= hidden,\n",
        "        tol=0.00001, n_iter_no_change=25,\n",
        "        warm_start=False, early_stopping=True,\n",
        "        learning_rate=\"adaptive\", learning_rate_init=0.001,\n",
        "        max_iter=iters)\n",
        "    dtstart = dt.now()\n",
        "    print(\"      model created \", dt.now())\n",
        "    mod.fit(Known, y)\n",
        "    print(\"      model   fit   \", dt.now())\n",
        "\n",
        "    print(\"      \", mod.score(Known, y))\n",
        "\n",
        "    print (\"      \", dt.now() - dtstart)\n",
        "    print (\"      \", mod.n_iter_)\n",
        "\n",
        "    # print(\"      \", dt.now())\n",
        "  \n",
        "  #### end for\n",
        "  print('end   ', hidden, dt.now())\n",
        "#### end for\n",
        "print('end', iters, dt.now())\n",
        "\n",
        "Summary : no models converging at 500 iters - - set max to 1000 - want some to converge\n",
        " more complex models are producing better early results - buy evening out later - but still somewhat better\n",
        " the third layer is definitely helping - try four but overfitting is a prob here\n",
        " nodes per layer is not doing much - anything greater than feature count doesn't seen useful\n",
        "\n",
        "\n",
        "     (10, 10) 25\n",
        "      Fitting model and checking score on Known data 25 iterations\n",
        "      model created  2019-10-10 09:33:31.360755\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:33:37.181152\n",
        "       0.04900702143306124\n",
        "       0:00:05.857442\n",
        "       25\n",
        "\n",
        "     (15, 10) 25\n",
        "      Fitting model and checking score on Known data 25 iterations\n",
        "      model created  2019-10-10 09:33:37.224805\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:33:43.423821\n",
        "       0.055618036857014164\n",
        "       0:00:06.236897\n",
        "       25\n",
        "\n",
        "     (20, 10) 25\n",
        "      Fitting model and checking score on Known data 25 iterations\n",
        "      model created  2019-10-10 09:33:43.468912\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:33:49.711396\n",
        "       0.08391504732899813\n",
        "       0:00:06.285070\n",
        "       25\n",
        "\n",
        "     (20, 20) 25\n",
        "      Fitting model and checking score on Known data 25 iterations\n",
        "      model created  2019-10-10 09:33:49.761121\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:33:56.333045\n",
        "       0.0845487845042745\n",
        "       0:00:06.621983\n",
        "       25\n",
        "\n",
        "     (20, 10, 5) 25\n",
        "      Fitting model and checking score on Known data 25 iterations\n",
        "      model created  2019-10-10 09:33:56.390643\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:34:03.908871\n",
        "       0.5890762607476452\n",
        "       0:00:07.566957\n",
        "       25\n",
        "\n",
        "     (20, 20, 10) 25\n",
        "      Fitting model and checking score on Known data 25 iterations\n",
        "      model created  2019-10-10 09:34:03.966853\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:34:12.095002\n",
        "       0.7680736717882629\n",
        "       0:00:08.189435\n",
        "       25\n",
        "end    (20, 20, 10) 2019-10-10 09:34:12.156425\n",
        "\n",
        "     (10, 10) 100\n",
        "      Fitting model and checking score on Known data 100 iterations\n",
        "      model created  2019-10-10 09:34:12.164679\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:34:40.489466\n",
        "       0.7631855019633931\n",
        "       0:00:28.376282\n",
        "       100\n",
        "\n",
        "     (15, 10) 100\n",
        "      Fitting model and checking score on Known data 100 iterations\n",
        "      model created  2019-10-10 09:34:40.550196\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:35:12.858821\n",
        "       0.7381185626688946\n",
        "       0:00:32.376740\n",
        "       100\n",
        "\n",
        "     (20, 10) 100\n",
        "      Fitting model and checking score on Known data 100 iterations\n",
        "      model created  2019-10-10 09:35:12.935919\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:35:40.034723\n",
        "       0.7636492674828678\n",
        "       0:00:27.148139\n",
        "       100\n",
        "\n",
        "     (20, 20) 100\n",
        "      Fitting model and checking score on Known data 100 iterations\n",
        "      model created  2019-10-10 09:35:40.093492\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:36:24.381839\n",
        "       0.7786494832713816\n",
        "       0:00:44.390218\n",
        "       100\n",
        "\n",
        "     (20, 10, 5) 100\n",
        "      Fitting model and checking score on Known data 100 iterations\n",
        "      model created  2019-10-10 09:36:24.493112\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:37:06.415136\n",
        "       0.7895194173603781\n",
        "       0:00:42.014290\n",
        "       100\n",
        "\n",
        "     (20, 20, 10) 100\n",
        "      Fitting model and checking score on Known data 100 iterations\n",
        "      model created  2019-10-10 09:37:06.516429\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:37:58.232064\n",
        "       0.7920320608715972\n",
        "       0:00:51.830771\n",
        "       100\n",
        "end    (20, 20, 10) 2019-10-10 09:37:58.347585\n",
        "\n",
        "     (10, 10) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 09:37:58.356871\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:41:55.503532\n",
        "       0.7980891796367898\n",
        "       0:03:57.245916\n",
        "       500\n",
        "\n",
        "     (15, 10) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 09:41:55.611581\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:45:27.954997\n",
        "       0.8315259032349603\n",
        "       0:03:32.439927\n",
        "       500\n",
        "\n",
        "     (20, 10) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 09:45:28.060818\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:49:42.244395\n",
        "       0.7926614899392772\n",
        "       0:04:14.301349\n",
        "       500\n",
        "\n",
        "     (20, 20) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 09:49:42.370786\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 09:54:40.780235\n",
        "       0.7934448999872588\n",
        "       0:04:58.561461\n",
        "       500\n",
        "\n",
        "     (20, 10, 5) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 09:54:40.940533\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:00:09.746135\n",
        "       0.8455746791204602\n",
        "       0:05:28.962986\n",
        "       500\n",
        "\n",
        "     (20, 20, 10) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 10:00:09.911843\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:07:40.174202\n",
        "       0.8564149216340179\n",
        "       0:07:30.512693\n",
        "       500\n",
        "end    (20, 20, 10) 2019-10-10 10:07:40.424942\n",
        "end 500 2019-10-10 10:07:40.425557"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MLI0bGQWJ4E",
        "colab_type": "text"
      },
      "source": [
        "#### add some more loops \n",
        "#### and complete investigation of data = ref above\n",
        "\n",
        "for iters in [ 200, 500, 1000] :\n",
        "  for hidden in [(5,), (10,), (20,), (30,),\n",
        "                 (10,5), (10,10), (15,10), (20, 10), (20,20),\n",
        "                 (15,10,5), (20,10,5), (20,20,10), (20,20,20), (30,20,20),\n",
        "                 (30,20,10,5), (40,30,20,10)] :\n",
        "    print (\"\\n    \",hidden,iters)\n",
        "    print(\"      Fitting model and checking score on Known data\" , iters, \"iterations\")\n",
        "    Known = train_norm.copy()\n",
        "    y = train_df[\"Income\"].copy()\n",
        "\n",
        "\n",
        "    #mod = linear_model.BayesianRidge(copy_X=False, n_iter=1000)\n",
        "    mod = nnet.MLPRegressor(\n",
        "        hidden_layer_sizes= hidden,\n",
        "        tol=0.00001, n_iter_no_change=25,\n",
        "        warm_start=False, early_stopping=True,\n",
        "        learning_rate=\"adaptive\", learning_rate_init=0.001,\n",
        "        max_iter=iters)\n",
        "    dtstart = dt.now()\n",
        "    print(\"      model created \", dt.now())\n",
        "    mod.fit(Known, y)\n",
        "    print(\"      model   fit   \", dt.now())\n",
        "\n",
        "    print(\"      \", mod.score(Known, y))\n",
        "\n",
        "    print (\"      \", dt.now() - dtstart)\n",
        "    print (\"      \", mod.n_iter_)\n",
        "\n",
        "    # print(\"      \", dt.now())\n",
        "  \n",
        "  #### end for\n",
        "  print('end   ', hidden, dt.now())\n",
        "#### end for\n",
        "print('end', iters, dt.now())\n",
        "\n",
        "\n",
        "     (5,) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 10:47:53.279856\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:48:34.999418\n",
        "       0.0301556793972817\n",
        "       0:00:41.767894\n",
        "       200\n",
        "\n",
        "     (10,) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 10:48:35.057482\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:49:34.629549\n",
        "       0.04285950838693875\n",
        "       0:00:59.673996\n",
        "       200\n",
        "\n",
        "     (20,) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 10:49:34.739504\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:51:02.904169\n",
        "       0.07462261255991953\n",
        "       0:01:28.324141\n",
        "       200\n",
        "\n",
        "     (30,) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 10:51:03.072470\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:52:40.152883\n",
        "       0.09203066164729579\n",
        "       0:01:37.260335\n",
        "       200\n",
        "\n",
        "     (10, 5) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 10:52:40.340696\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:53:45.957755\n",
        "       0.7832534740463617\n",
        "       0:01:05.684780\n",
        "       200\n",
        "\n",
        "     (10, 10) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 10:53:46.033686\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:54:40.955478\n",
        "       0.7850835855529952\n",
        "       0:00:54.985810\n",
        "       200\n",
        "\n",
        "     (15, 10) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 10:54:41.026800\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:56:16.265144\n",
        "       0.7673073991327266\n",
        "       0:01:35.330512\n",
        "       200\n",
        "\n",
        "     (20, 10) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 10:56:16.365361\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:57:33.593557\n",
        "       0.7889710988838171\n",
        "       0:01:17.315888\n",
        "       200\n",
        "\n",
        "     (20, 20) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 10:57:33.688786\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 10:59:34.324738\n",
        "       0.7913538372356332\n",
        "       0:02:00.801470\n",
        "       200\n",
        "\n",
        "     (15, 10, 5) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 10:59:34.498081\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:01:34.864933\n",
        "       0.7976181864823924\n",
        "       0:02:00.530229\n",
        "       200\n",
        "\n",
        "     (20, 10, 5) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 11:01:35.035162\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:03:22.277670\n",
        "       0.7737864276447246\n",
        "       0:01:47.415397\n",
        "       200\n",
        "\n",
        "     (20, 20, 10) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 11:03:22.459616\n",
        "      model   fit    2019-10-10 11:03:53.431633\n",
        "       0.7733266447391471\n",
        "       0:00:31.034126\n",
        "       51\n",
        "\n",
        "     (20, 20, 20) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 11:03:53.501830\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:07:11.690534\n",
        "       0.7937762169947458\n",
        "       0:03:18.476095\n",
        "       200\n",
        "\n",
        "     (30, 20, 20) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 11:07:11.985765\n",
        "      model   fit    2019-10-10 11:07:40.799254\n",
        "       0.7750146059353649\n",
        "       0:00:28.897938\n",
        "       46\n",
        "\n",
        "     (30, 20, 10, 5) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 11:07:40.892631\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:09:58.090239\n",
        "       0.8568734197234469\n",
        "       0:02:17.381845\n",
        "       200\n",
        "\n",
        "     (40, 30, 20, 10) 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 11:09:58.282941\n",
        "      model   fit    2019-10-10 11:14:02.810882\n",
        "       0.8626491700410276\n",
        "       0:04:04.942987\n",
        "       142\n",
        "end    (40, 30, 20, 10) 2019-10-10 11:14:03.226315\n",
        "\n",
        "     (5,) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:14:03.234809\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:16:04.651846\n",
        "       0.09903122752584081\n",
        "       0:02:01.463704\n",
        "       500\n",
        "\n",
        "     (10,) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:16:04.706154\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:19:24.725476\n",
        "       0.13117170821488644\n",
        "       0:03:20.122126\n",
        "       500\n",
        "\n",
        "     (20,) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:19:24.836969\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:23:33.214167\n",
        "       0.23202836565720794\n",
        "       0:04:08.512761\n",
        "       500\n",
        "\n",
        "     (30,) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:23:33.357707\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:30:54.653542\n",
        "       0.2704900449221047\n",
        "       0:07:21.552933\n",
        "       500\n",
        "\n",
        "     (10, 5) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:30:54.918668\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:33:51.424327\n",
        "       0.7720991503694135\n",
        "       0:02:56.588295\n",
        "       500\n",
        "\n",
        "     (10, 10) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:33:51.514666\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:36:47.930751\n",
        "       0.7772539269656454\n",
        "       0:02:56.492939\n",
        "       500\n",
        "\n",
        "     (15, 10) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:36:48.015299\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:40:40.848851\n",
        "       0.792650835667579\n",
        "       0:03:52.931769\n",
        "       500\n",
        "\n",
        "     (20, 10) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:40:40.955014\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:45:44.520795\n",
        "       0.7931742089692261\n",
        "       0:05:03.697908\n",
        "       500\n",
        "\n",
        "     (20, 20) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:45:44.660703\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:51:33.721849\n",
        "       0.7932036862072729\n",
        "       0:05:49.242339\n",
        "       500\n",
        "\n",
        "     (15, 10, 5) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:51:33.911474\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 11:55:59.999190\n",
        "       0.8292438695614517\n",
        "       0:04:26.202548\n",
        "       500\n",
        "\n",
        "     (20, 10, 5) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 11:56:00.122033\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 12:00:43.992710\n",
        "       0.8584364840583849\n",
        "       0:04:43.980424\n",
        "       500\n",
        "\n",
        "     (20, 20, 10) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 12:00:44.110394\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 12:06:53.798825\n",
        "       0.8625297588193361\n",
        "       0:06:09.861295\n",
        "       500\n",
        "\n",
        "     (20, 20, 20) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 12:06:53.980181\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 12:14:39.013617\n",
        "       0.8576937540307676\n",
        "       0:07:45.299008\n",
        "       500\n",
        "\n",
        "     (30, 20, 20) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 12:14:39.287546\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 12:24:53.280863\n",
        "       0.8493605467070405\n",
        "       0:10:14.335360\n",
        "       500\n",
        "\n",
        "     (30, 20, 10, 5) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 12:24:53.631465\n",
        "      model   fit    2019-10-10 12:32:02.203261\n",
        "       0.8630160098707162\n",
        "       0:07:08.868963\n",
        "       327\n",
        "\n",
        "     (40, 30, 20, 10) 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 12:32:02.509804\n",
        "      model   fit    2019-10-10 12:36:29.186057\n",
        "       0.861921476374926\n",
        "       0:04:27.114403\n",
        "       166\n",
        "end    (40, 30, 20, 10) 2019-10-10 12:36:29.624619\n",
        "\n",
        "     (5,) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 12:36:29.633280\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 12:40:49.709176\n",
        "       0.25959580135316507\n",
        "       0:04:20.125678\n",
        "       1000\n",
        "\n",
        "     (10,) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 12:40:49.767559\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 12:45:19.223582\n",
        "       0.49181449517528864\n",
        "       0:04:29.507899\n",
        "       1000\n",
        "\n",
        "     (20,) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 12:45:19.283679\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 12:52:41.766734\n",
        "       0.6848908729049296\n",
        "       0:07:22.589052\n",
        "       1000\n",
        "\n",
        "     (30,) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 12:52:41.881513\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 13:03:15.167647\n",
        "       0.7259753694756534\n",
        "       0:10:33.452365\n",
        "       1000\n",
        "\n",
        "     (10, 5) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 13:03:15.341926\n",
        "      model   fit    2019-10-10 13:03:21.657213\n",
        "       -0.531387441515947\n",
        "       0:00:06.346316\n",
        "       27\n",
        "\n",
        "     (10, 10) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 13:03:21.695385\n",
        "      model   fit    2019-10-10 13:07:04.630560\n",
        "       0.7910691164220829\n",
        "       0:03:43.050278\n",
        "       438\n",
        "\n",
        "     (15, 10) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 13:07:04.752840\n",
        "      model   fit    2019-10-10 13:08:01.169633\n",
        "       0.7814409610428632\n",
        "       0:00:56.496408\n",
        "       160\n",
        "\n",
        "     (20, 10) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 13:08:01.255946\n",
        "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "      model   fit    2019-10-10 13:17:47.886507\n",
        "       0.7960003670605276\n",
        "       0:09:46.763366\n",
        "       1000\n",
        "\n",
        "     (20, 20) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 13:17:48.026805\n",
        "      model   fit    2019-10-10 13:25:21.638235\n",
        "       0.7937293152719301\n",
        "       0:07:33.798122\n",
        "       593\n",
        "\n",
        "     (15, 10, 5) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 13:25:21.833161\n",
        "      model   fit    2019-10-10 13:29:24.716626\n",
        "       0.8568137796510888\n",
        "       0:04:02.978032\n",
        "       504\n",
        "\n",
        "     (20, 10, 5) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 13:29:24.819418\n",
        "      model   fit    2019-10-10 13:30:08.998374\n",
        "       0.7839810296899453\n",
        "       0:00:44.255734\n",
        "       104\n",
        "\n",
        "     (20, 20, 10) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 13:30:09.082897\n",
        "      model   fit    2019-10-10 13:37:56.412566\n",
        "       0.8602100046874072\n",
        "       0:07:47.555383\n",
        "       481\n",
        "\n",
        "     (20, 20, 20) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 13:37:56.646549\n",
        "      model   fit    2019-10-10 13:44:58.933620\n",
        "       0.861849639610157\n",
        "       0:07:02.564611\n",
        "       441\n",
        "\n",
        "     (30, 20, 20) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 13:44:59.218951\n",
        "      model   fit    2019-10-10 14:01:50.655469\n",
        "       0.8629787727866067\n",
        "       0:16:51.724465\n",
        "       834\n",
        "\n",
        "     (30, 20, 10, 5) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 14:01:50.951668\n",
        "      model   fit    2019-10-10 14:02:03.020741\n",
        "       -0.5313979009896326\n",
        "       0:00:12.164888\n",
        "       27\n",
        "\n",
        "     (40, 30, 20, 10) 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 14:02:03.124643\n",
        "      model   fit    2019-10-10 14:10:38.939692\n",
        "       0.8647387360072559\n",
        "       0:08:36.349094\n",
        "       214\n",
        "end    (40, 30, 20, 10) 2019-10-10 14:10:39.474205\n",
        "end 1000 2019-10-10 14:10:39.474884\n",
        "\n",
        "===================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8_uHuesdtc0",
        "colab_type": "text"
      },
      "source": [
        "#### add some more loops \n",
        "#### and complete investigation of data = ref above\n",
        "\n",
        "\n",
        "#### for hidden in [(5,), (10,), (20,), (30,), (10,5), (10,10), (15,10), (20, 10), (20,20), (15,10,5), (20,10,5), (20,20,10), (20,20,20), (30,20,20), (30,20,10,5), (40,30,20,10)] :\n",
        "for dpth in [2,3,4,5,6,7,8,9,10] :\n",
        "  for iters in [200, 500, 1000] :\n",
        "    print (\"\\n    \",dpth,iters)\n",
        "    # print (\"\\n    \",hidden,iters)\n",
        "    print(\"      Fitting model and checking score on Known data\" , iters, \"iterations\")\n",
        "    Known = train_norm.copy()\n",
        "    y = train_df[\"Income\"].copy()\n",
        "\n",
        "\n",
        "    #mod = linear_model.BayesianRidge(copy_X=False, tol=0.00001, n_iter=1000)\n",
        "    # 0.7349053641228902\n",
        "        \n",
        "    # mod = nnet.MLPRegressor(\n",
        "    #     hidden_layer_sizes= hidden,\n",
        "    #     tol=0.00001, n_iter_no_change=25,\n",
        "    #     warm_start=False, early_stopping=True,\n",
        "    #     learning_rate=\"adaptive\", learning_rate_init=0.001,\n",
        "    #     max_iter=iters)\n",
        "        \n",
        "    # mod = ensemble.AdaBoostRegressor( n_estimators=100 )\n",
        "    # doesn't work   \n",
        "    \n",
        "    # mod = svm.LinearSVR( tol=1e-5, max_iter =10000)\n",
        "    # doesn't work\n",
        "    \n",
        "    # mod = ensemble.RandomForestRegressor(max_depth=7, n_estimators=1000)\n",
        "    # 0.8288730954198963 in 6:06 - (max_depth=7, n_estimators=1000)\n",
        "    mod = ensemble.RandomForestRegressor(max_depth=dpth, n_estimators=(iters*2))\n",
        "    \n",
        "    \n",
        "    dtstart = dt.now()\n",
        "    print(\"      model created \", dt.now())\n",
        "    mod.fit(Known, y)\n",
        "    print(\"      model   fit   \", dt.now())\n",
        "\n",
        "    print(\"      \", mod.score(Known, y))\n",
        "\n",
        "    print (\"      \", dt.now() - dtstart)\n",
        "    # print (\"      \", mod.n_iter_)\n",
        "\n",
        "    # print(\"      \", dt.now())\n",
        "  \n",
        "  #### end for\n",
        "  print('end   ', hidden, dt.now())\n",
        "#### end for\n",
        "print('end', iters, dt.now())\n",
        "\n",
        "\n",
        "     2 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 20:21:14.378696\n",
        "      model   fit    2019-10-10 20:21:53.271866\n",
        "       0.5736229175179561\n",
        "       0:00:39.625358\n",
        "\n",
        "     2 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 20:21:54.010832\n",
        "      model   fit    2019-10-10 20:23:31.236617\n",
        "       0.5741663052074726\n",
        "       0:01:39.011410\n",
        "\n",
        "     2 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 20:23:33.030093\n",
        "      model   fit    2019-10-10 20:26:47.926798\n",
        "       0.573818832838402\n",
        "       0:03:18.454079\n",
        "end    (5,) 2019-10-10 20:26:51.484233\n",
        "\n",
        "     3 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 20:26:51.492473\n",
        "      model   fit    2019-10-10 20:27:49.851387\n",
        "       0.6468803160380183\n",
        "       0:00:59.477994\n",
        "\n",
        "     3 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 20:27:50.977921\n",
        "      model   fit    2019-10-10 20:30:18.564119\n",
        "       0.647037094860585\n",
        "       0:02:30.352967\n",
        "\n",
        "     3 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 20:30:21.338211\n",
        "      model   fit    2019-10-10 20:35:10.315396\n",
        "       0.646929737395626\n",
        "       0:04:54.480224\n",
        "end    (5,) 2019-10-10 20:35:15.818480\n",
        "\n",
        "     4 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 20:35:15.826252\n",
        "      model   fit    2019-10-10 20:36:33.224299\n",
        "       0.71350731028145\n",
        "       0:01:18.926923\n",
        "\n",
        "     4 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 20:36:34.760355\n",
        "      model   fit    2019-10-10 20:39:48.039133\n",
        "       0.7134267631787063\n",
        "       0:03:17.100182\n",
        "\n",
        "     4 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 20:39:51.868232\n",
        "      model   fit    2019-10-10 20:46:20.172737\n",
        "       0.7138412086345978\n",
        "       0:06:35.992590\n",
        "end    (5,) 2019-10-10 20:46:27.861367\n",
        "\n",
        "     5 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 20:46:27.870368\n",
        "      model   fit    2019-10-10 20:48:04.621877\n",
        "       0.7638178338532969\n",
        "       0:01:38.736253\n",
        "\n",
        "     5 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 20:48:06.613606\n",
        "      model   fit    2019-10-10 20:52:06.734462\n",
        "       0.7646974230780095\n",
        "       0:04:04.998221\n",
        "\n",
        "     5 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 20:52:11.620979\n",
        "      model   fit    2019-10-10 21:00:25.314945\n",
        "       0.764601623113888\n",
        "       0:08:23.646865\n",
        "end    (5,) 2019-10-10 21:00:35.267901\n",
        "\n",
        "     6 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 21:00:35.277276\n",
        "      model   fit    2019-10-10 21:02:35.534353\n",
        "       0.7997715178561466\n",
        "       0:02:02.763652\n",
        "\n",
        "     6 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 21:02:38.049580\n",
        "      model   fit    2019-10-10 21:07:31.927603\n",
        "       0.8000867207667924\n",
        "       0:05:00.144226\n",
        "\n",
        "     6 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 21:07:38.203885\n",
        "      model   fit    2019-10-10 21:17:31.549466\n",
        "       0.8000346637288746\n",
        "       0:10:05.545628\n",
        "end    (5,) 2019-10-10 21:17:43.749597\n",
        "\n",
        "     7 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 21:17:43.761069\n",
        "      model   fit    2019-10-10 21:20:07.109243\n",
        "       0.8290575989685841\n",
        "       0:02:26.446109\n",
        "\n",
        "     7 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 21:20:10.217641\n",
        "      model   fit    2019-10-10 21:26:08.829432\n",
        "       0.828835231317038\n",
        "       0:06:06.163957\n",
        "\n",
        "     7 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 21:26:16.391610\n",
        "      model   fit    2019-10-10 21:38:09.373842\n",
        "       0.8289241629173437\n",
        "       0:12:08.234684\n",
        "end    (5,) 2019-10-10 21:38:24.626338\n",
        "\n",
        "     8 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 21:38:24.642633\n",
        "      model   fit    2019-10-10 21:41:07.478943\n",
        "       0.8520613508354745\n",
        "       0:02:46.457555\n",
        "\n",
        "     8 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 21:41:11.111212\n",
        "      model   fit    2019-10-10 21:47:58.171818\n",
        "       0.8523351397135295\n",
        "       0:06:56.118656\n",
        "\n",
        "     8 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 21:48:07.243463\n",
        "      model   fit    2019-10-10 22:02:35.772508\n",
        "       0.8521770569895661\n",
        "       0:14:47.289448\n",
        "end    (5,) 2019-10-10 22:02:54.532980\n",
        "\n",
        "     9 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 22:02:54.562003\n",
        "      model   fit    2019-10-10 22:06:05.381423\n",
        "       0.8750031721060594\n",
        "       0:03:15.244867\n",
        "\n",
        "     9 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 22:06:09.823157\n",
        "      model   fit    2019-10-10 22:14:09.328025\n",
        "       0.8748725402808654\n",
        "       0:08:10.449822\n",
        "\n",
        "     9 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 22:14:20.296168\n",
        "      model   fit    2019-10-10 22:30:32.273443\n",
        "       0.8747737504863684\n",
        "       0:16:33.890412\n",
        "end    (5,) 2019-10-10 22:30:54.186726\n",
        "\n",
        "     10 200\n",
        "      Fitting model and checking score on Known data 200 iterations\n",
        "      model created  2019-10-10 22:30:54.222973\n",
        "      model   fit    2019-10-10 22:34:21.119760\n",
        "       0.8965588330934611\n",
        "       0:03:32.017769\n",
        "\n",
        "     10 500\n",
        "      Fitting model and checking score on Known data 500 iterations\n",
        "      model created  2019-10-10 22:34:26.259523\n",
        "      model   fit    2019-10-10 22:43:03.942714\n",
        "       0.8967560340536448\n",
        "       0:08:50.348551\n",
        "\n",
        "     10 1000\n",
        "      Fitting model and checking score on Known data 1000 iterations\n",
        "      model created  2019-10-10 22:43:16.639438\n",
        "      model   fit    2019-10-10 22:59:36.513166\n",
        "       0.8968737557325714\n",
        "       0:16:44.478299\n",
        "end    (5,) 2019-10-10 23:00:01.117808\n",
        "end 1000 2019-10-10 23:00:01.118255\n",
        "\n",
        "======================================================"
      ]
    }
  ]
}
