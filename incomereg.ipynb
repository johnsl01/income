{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "incomereg.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnsl01/income/blob/master/incomereg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owm9n3f8eQjs",
        "colab_type": "text"
      },
      "source": [
        "#_\n",
        "_Multiple variable (hyperplane) regression_\n",
        "Income data \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8hTCMa9mKAm",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "_ml outline approach_\n",
        "\n",
        "A structured ML student exercise type task typically comprises a set of data with one or more answers per data sample and a second set of data with the answers missing.\n",
        "\n",
        "The basic task is to use machine learning to provide the missing answers.\n",
        "\n",
        "The normal approach is : \n",
        "\n",
        "Explore and understand the data provided - typically producing some basic metrics around the data and preparing some simple correlations between elements of the data and the answers.\n",
        "\n",
        "Assess the quality of the data - normally carried out as part of the exploration this task is more concentrating on the missing and bad data and any extreme outliers - and also looking at any unstructured data (free text strings etc) and determining what remediation is necessary to either impute the missing data - discard samples or manipulate the unstructured data to generate structured elements from it.\n",
        "\n",
        "Carry out some initial ML tasks such as linear (planar) regression and assess the quality of the results on the known answers and provide an initial version of the answers to use as a benchmark for more sophisticated next steps.\n",
        "\n",
        "Make an assesssment based on the information gathered above on the approach to ML - what types of ML tools are approriate to the data and estimate what level of quality could be achieved. For a student / training exercise the requirement may be to consider more than one aproach and to compare the results - or the requirement may be simply to produce the best result, and in this case there may be a submission so the 'real' answers are hidden and only a score available to compare results.\n",
        "\n",
        "Student exercise can also contain more specific requirements - to use a specific type of ML approach and to demonstrate the impacts of some parameter changes or to examine the impact of onder or over fitting to the test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKpZBTxsm4Dk",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "_discription and general notes_\n",
        "\n",
        "y = B0 + B1.X1 + B2.X2 + B3.X3 ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w8maXdCnSNf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIZnfvuMlJqK",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "imports and data loads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fldw8f0uaRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title                 Imports               #\n",
        "###############################################\n",
        "print (\"Imports\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "\n",
        "# !pip install fancyimpute\n",
        "# import fancyimpute as fi\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from datetime import datetime\n",
        "print (datetime.now())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7oKOzJslmyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title               Data loads              #\n",
        "###############################################\n",
        "print (\"Data loads\")\n",
        "sourcedata = \"https://raw.githubusercontent.com/johnsl01/income/master/incomeknown.csv\"\n",
        "incomeknown_df = pd.read_csv(sourcedata, sep=\",\")\n",
        "\n",
        "print (datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvy6G37Vs-84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at the data \n",
        "incomeknown_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjaNDmzis37i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dont like the col names - much easier with simple strings with no spaces.\n",
        "incomeknown_df.rename(columns = {\"Year of Record\" : \"Year\",\n",
        "                              \"Size of City\" : \"CitySize\",\n",
        "                              \"University Degree\" : \"Degree\",\n",
        "                              \"Wears Glasses\" : \"Glasses\",\n",
        "                              \"Hair Color\" : \"Hair\",\n",
        "                              \"Body Height [cm]\" : \"Height\",\n",
        "                              \"Income in EUR\" : \"Income\"},\n",
        "                      inplace = True)\n",
        "\n",
        "print (datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoUmGfOWuKnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look again \n",
        "incomeknown_df.tail(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nTndBoG5JsE",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "_Initial data exploration_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAOfl9Ne5Tjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomeknown_df.describe()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxS34kwLsFUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomeknown_df[['Gender','Country','Profession','Degree','Hair']].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eULCQbzD7Bcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXbiPY30qOUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAlHGCzJAdTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkzNAc40qP8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ( incomeknown_df['Profession'].value_counts() )\n",
        "\n",
        "print ( incomeknown_df['Degree'].value_counts() )\n",
        "\n",
        "print ( incomeknown_df['Hair'].value_counts() )\n",
        "\n",
        "print ( incomeknown_df['Country'].value_counts() )\n",
        "\n",
        "print ( incomeknown_df['Gender'].value_counts() )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mTR5COj7FxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare some simple histograms and scatter plots of numeric data against income\n",
        "# looking for any obvious correlation\n",
        "\n",
        "# exclude outliers (particulalry high incomes) to make the plots more useful\n",
        "\n",
        "# \n",
        "\n",
        "# incomeknown_df.hist(\"Year\", bins=40)\n",
        "# incomeknown_df.loc[incomeknown_df.Income < 1000000].plot.scatter(x = \"Year\", y = \"Income\")\n",
        "\n",
        "# print (\"Scater plot of Income by Year\")\n",
        "plt.scatter(incomeknown_df.loc[incomeknown_df.Income < 60000][\"Year\"], incomeknown_df.loc[incomeknown_df.Income < 60000][\"Income\"], alpha=0.0075)\n",
        "plt.title('Scatter plot of Income by Year')\n",
        "\n",
        "incomeknown_df.loc[incomeknown_df.Income < 500000].hist(\"Income\", bins=300)\n",
        "\n",
        "\n",
        "# incomeknown_df.hist(\"Age\")\n",
        "# incomeknown_df.loc[incomeknown_df.Income < 1000000].plot.scatter(x = \"Age\", y = \"Income\")\n",
        "\n",
        "incomeknown_df.hist(\"Height\", bins=200)\n",
        "incomeknown_df.loc[incomeknown_df.Income < 100000].plot.scatter(x = \"Height\", y = \"Income\", alpha=0.005)\n",
        "\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                  (incomeknown_df.Gender == \"male\")].hist(\"Height\", bins=300)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                   (incomeknown_df.Gender == \"male\")].plot.scatter(x = \"Height\", y = \"Income\", c=\"LightBlue\", alpha=0.01)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                   (incomeknown_df.Gender == \"female\")].hist(\"Height\", bins=300)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                   (incomeknown_df.Gender == \"female\")].plot.scatter(x = \"Height\", y = \"Income\", c = 'Pink', alpha=0.01)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                   ((incomeknown_df.Gender != \"female\") & (incomeknown_df.Gender != \"male\"))].hist(\"Height\", bins=300)\n",
        "\n",
        "incomeknown_df.loc[(incomeknown_df.Income < 100000) & \n",
        "                   ((incomeknown_df.Gender != \"female\") & (incomeknown_df.Gender != \"male\"))].plot.scatter(x = \"Height\", y = \"Income\", c = 'Grey', alpha=0.02)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pYM3PXD-7NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomeknown_df.loc[incomeknown_df.Age > 105]\n",
        "# incomeknown_df.loc[incomeknown_df.Income > 2000000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu9oLz_slSY0",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adqBJ-dHP9BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"def predict(X, theta)\")\n",
        "def predict(X, theta):\n",
        "  # takes m by n matrix X as input and returns an m by 1 vector \n",
        "  # containing the predictions h_theta(x^i) for each row x^i, i=1,...,m in X\n",
        "  ##### replace the next line with your code #####\n",
        "  \n",
        "  # This is the generic multiple variable implementation. \n",
        "  \n",
        "  # For conveniece each data point in X has an initial 1 \n",
        "  #   added to enable the B0 coeficient to be applied efficiently\n",
        "  \n",
        "  # print(X)\n",
        "  # print(theta)\n",
        "  # print(X.shape)\n",
        "  \n",
        "  # Get the number of coeficients B0, B1 ..... \n",
        "  #   we iterate over these\n",
        "  n=len(theta)\n",
        "  \n",
        "  # For the multiple linear regression we need to iterate over the \n",
        "  #   length of theta \n",
        "  # This assumes a simple B0 + B1.X1 + B2.X2 + ....\n",
        "  #   it does not consider more complex dependencies\n",
        "  #   such as B0 + B1.X1 + B2.X2 + B3.X1.X2   etc.\n",
        "  #   these require the X to be constructed to meet the requirement\n",
        "  #   and may introduce too much colinearity.\n",
        "  \n",
        "  # Check for single data point\n",
        "  #   requires a special case as it arrives as 1D, rather than 2D\n",
        "  #   and if it does arrive as 2D the else handles it anyway\n",
        "  \n",
        "  # Numpy doesn't appear to support a mechanism to directly \n",
        "  #   multiply each row of an array by an equivalent sized vector\n",
        "  #   so we use a for loop to iterate over the vector but use \n",
        "  #   numpy maths, which are more efficient, to apply each element\n",
        "  #   of the theta vetor to the equivalent data variable for all points. \n",
        "   \n",
        "  if len(X.shape) == 1 : \n",
        "    # this is the edge case for a single data point in a vector\n",
        "    pred = X[0] * theta[0] \n",
        "    for i in range(1,n) :\n",
        "      pred = pred + X[i]*theta[i]  \n",
        "        \n",
        "  else : \n",
        "    #this is the general case for data point(s) in an array\n",
        "    pred = X[:,0]*theta[0] \n",
        "    for i in range(1,n) :\n",
        "      pred = pred + X[:,i]*theta[i]    \n",
        "        \n",
        "  # print(pred)\n",
        "  \n",
        "  # Return the prediction\n",
        "  # The returned value is a vector of value for each data point.\n",
        "  return pred\n",
        "# end def predict\n",
        "\n",
        "\n",
        "print(\"def computeCost(X, y, theta)\")\n",
        "def computeCost(X, y, theta):\n",
        "  # function calculates the cost J(theta) and return its value\n",
        "  ##### replace the next line with your code #####\n",
        "  \n",
        "  # this function is already independent of the number of variables\n",
        "  # provided the X array carries the data with a leading 1 on each data point\n",
        "  # and the theta has the same number of B0, B1, B2 ...  values.\n",
        "  \n",
        "  # Get the value(s) predicted by the current theta values\n",
        "  costpred = predict (X,theta)\n",
        "  \n",
        "  # get the difference(s) between the predictions and the actuals\n",
        "  costbase = costpred - y\n",
        "    \n",
        "  # get the square of the difference(s)\n",
        "  costsq = costbase **2\n",
        "  \n",
        "  # get the sum of the squared difference(s)\n",
        "  sumcost = costsq.sum() \n",
        "  \n",
        "  # divide the sum of squares by twice the number of data points\n",
        "  cost = sumcost/(2*len(y))  \n",
        "  \n",
        "  # return the cost of the current theta values\n",
        "  # the returned value is a numeric value of the cost.\n",
        "  return cost\n",
        "# end def computeCost\n",
        "\n",
        "\n",
        "\n",
        "print(\"def computeGradient(X, y, theta)\")\n",
        "def computeGradient(X, y, theta):\n",
        "  # function calulate the gradient of J(theta) and returns its value\n",
        "  ##### replace the next line with your code #####\n",
        "  # This function is already capable of delaing with multiple varables\n",
        "  # provided X (with a leading 1 per data point) and theta are matched sizes.\n",
        "  \n",
        "  # number of coeficients\n",
        "  n=len(theta)\n",
        "  # initiate the result\n",
        "  grad = np.zeros(n)\n",
        "  \n",
        "  # print (\"Number of coeficients: \" , n)\n",
        "  # print (\"Shapes of data, result and theta : \" , X.shape, y.shape, theta.shape)\n",
        "  # print (\"Types of  data, result and theta : \" , type(X), type(y), type(theta))\n",
        "  # print (\"Sample head of data\")\n",
        "  # for i in range(5) :\n",
        "      # print (X[i,:])\n",
        "    \n",
        "  # Get the value predicted by the current theta values\n",
        "  costpred = predict (X,theta)\n",
        "  # print (\"Compute Grad #2 :\", costpred.shape)\n",
        "  \n",
        "  # get the difference between the predictions and the actuals\n",
        "  costbase = costpred - y\n",
        "  # print (\"Compute Grad #3 :\", costbase.shape)  \n",
        "  \n",
        "  # calculate the gradient for each coefficient\n",
        "  # for is inefficient but it is used to iterate over a small\n",
        "  # range (1 more than the number of variables \n",
        "  # i.e the number of coefficients)\n",
        "  # while numpy array maths are used for the larger dimension\n",
        "  # (the number of data points)\n",
        "  for i in range(n) :\n",
        "    # get product of differences by current coeficients data point\n",
        "    costprod = costbase * X[:,i]\n",
        "    # print (\"Compute Grad #4 :\", costprod.shape) \n",
        "    # get the sum of the cost products\n",
        "    costprodsum = costprod.sum()\n",
        "    # print (\"Compute Grad #5 :\", costprodsum)\n",
        "    # divide by the number of data points\n",
        "    grad[i] = costprodsum / len(y)\n",
        "    # take this outside the for loop and use numpy maths ! \n",
        "    # print (\"Compute Grad #6 :\", grad[i])\n",
        "  # end for\n",
        "  # print (\"Compute Grad #6 :\", grad)\n",
        "  \n",
        "  # return the gradient\n",
        "  # the returned value of a vector of a gradient for each coeficient (theta) \n",
        "  return grad\n",
        "# end def computeGradient\n",
        "\n",
        "\n",
        "print(\"def gradDescent(X, y, theta, iters, alpha)\")\n",
        "def gradDescent(X, y, theta, iters, alpha):\n",
        "  # X - data (with the extra 1s in col 1)\n",
        "  # y - results - vector with 1 resilt per data point\n",
        "  # theta - B0, B1, B2 ... starting values \n",
        "  # iters - how many iterations\n",
        "  # alpha - adjustor for size of adjustment per step\n",
        "  \n",
        "  # returns : \n",
        "  # theta - B0, B1, B2 ... final values \n",
        "  # cost - cost after each iteration\n",
        "  \n",
        "  # initialize cost array\n",
        "  cost = np.zeros(iters)\n",
        "  \n",
        "  for i in range(iters):\n",
        "    theta = theta - alpha * computeGradient(X,y,theta)\n",
        "    cost[i] = computeCost(X, y, theta)\n",
        "\n",
        "  return theta, cost\n",
        "# end def gradientDescent   \n",
        "  \n",
        "\n",
        "print (datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vjjkR9X08NL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPkP3zRP09AL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"def gradientDescent(X, y, numparams)\")\n",
        "def gradientDescent(X, y, numparams):\n",
        "  # iteratively update parameter vector theta\n",
        "  # -- you should not modify this function\n",
        "\n",
        "  # initialize variables for learning rate and iterations\n",
        "  alpha = 0.02\n",
        "  iters = 5000\n",
        "  cost = np.zeros(iters)\n",
        "  theta= np.zeros(numparams)\n",
        "\n",
        "  for i in range(iters):\n",
        "    theta = theta - alpha * computeGradient(X,y,theta)\n",
        "    cost[i] = computeCost(X, y, theta)\n",
        "\n",
        "  return theta, cost\n",
        "\n",
        "\n",
        "\n",
        "print(\"def normaliseData(x)\")\n",
        "def normaliseData(x):\n",
        "  # rescale data to lie between 0 and 1\n",
        "  scale = x.max(axis=0)\n",
        "  return (x/scale, scale)\n",
        "\n",
        "\n",
        "\n",
        "print(\"def splitData(X, y)\")\n",
        "def splitData(X, y):\n",
        "  # split data into training and test parts\n",
        "  # ... for now, we use all of the data for training and testing\n",
        "  Xtrain=X; ytrain=y; Xtest=X; ytest=y\n",
        "  return (Xtrain, ytrain, Xtest, ytest)\n",
        "\n",
        "\n",
        "print (datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqEOQP5Z0-J-",
        "colab_type": "text"
      },
      "source": [
        "##_\n",
        "_main_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH7808b81TMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"def main()\")\n",
        "def main():\n",
        "  # load the data\n",
        "  # \"https://raw.githubusercontent.com/johnsl01/Titanic_Python/master/titanic_known.csv\"\n",
        "  data=np.loadtxt('https://raw.githubusercontent.com/johnsl01/linreg/master/stockprices.csv',usecols=(1,2))\n",
        "  X=data[:,0]\n",
        "  y=data[:,1]\n",
        "\n",
        "  # plot the data so we can see how it looks\n",
        "  # (output is in file graph.png)\n",
        "  fig, ax = plt.subplots(figsize=(12, 8))\n",
        "  ax.scatter(X, y, label='Data')\n",
        "  ax.set_xlabel('Amazon')\n",
        "  ax.set_ylabel('Google')\n",
        "  ax.set_title('Google stock price vs Amazon')\n",
        "  fig.savefig('graph.png')\n",
        "\n",
        "  # split the data into training and test parts\n",
        "  (Xtrain, ytrain, Xtest, ytest)=splitData(X,y)\n",
        "\n",
        "  # add a column of ones to input data\n",
        "  m=len(y) # m is number of training data points\n",
        "  Xtrain = np.column_stack((np.ones((m, 1)), Xtrain))\n",
        "  (m,n)=Xtrain.shape # m is number of data points, n number of features\n",
        "\n",
        "  # rescale training data to lie between 0 and 1\n",
        "  (Xt,Xscale) = normaliseData(Xtrain)\n",
        "  (yt,yscale) = normaliseData(ytrain)\n",
        "\n",
        "  # calculate the prediction\n",
        "  print('testing the prediction function ...')\n",
        "  theta=(1,2)\n",
        "  print('when x=[1,1] and theta is [1,2]) cost = ',predict(np.ones(n),theta))\n",
        "  print('approx expected prediction is 3')\n",
        "  print('when x=[[1,1],[5,5]] and theta is [1,2]) cost = ',predict(np.array([[1,1],[5,5]]),theta))\n",
        "  print('approx expected prediction is [3,15]')\n",
        "  input('Press Enter to continue...')\n",
        "\n",
        "  # calculate the cost when theta iz zero\n",
        "  print('testing the cost function ...')\n",
        "  theta=np.zeros(n)\n",
        "  print('when theta is zero cost = ',computeCost(Xt,yt,theta))\n",
        "  print('approx expected cost value is 0.318')\n",
        "  input('Press Enter to continue...')\n",
        "\n",
        "  # calculate the gradient when theta is zero\n",
        "  print('testing the gradient function ...')\n",
        "  print('when theta is zero gradient = ',computeGradient(Xt,yt,theta))\n",
        "  print('approx expected gradient value is [-0.79,-0.59]')\n",
        "  input('Press Enter to continue...')\n",
        "\n",
        "  # perform gradient descent to \"fit\" the model parameters\n",
        "  print('running gradient descent ...')\n",
        "  theta, cost = gradientDescent(Xt, yt, n)\n",
        "  print('after running gradientDescent() theta=',theta)\n",
        "  print('approx expected value is [0.34, 0.61]')\n",
        "\n",
        "  # plot some predictions\n",
        "  Xpred = np.linspace(X.min(), X.max(), 100)\n",
        "  Xpred = np.column_stack((np.ones((100, 1)), Xpred))\n",
        "  ypred = predict(Xpred/Xscale, theta)*yscale\n",
        "  fig, ax = plt.subplots(figsize=(12, 8))\n",
        "  ax.scatter(Xtest, ytest, color='b', label='Test Data')\n",
        "  ax.plot(Xpred[:,1], ypred, 'r', label='Prediction')\n",
        "  ax.set_xlabel('Amazon')\n",
        "  ax.set_ylabel('Google')\n",
        "  ax.legend(loc=2)\n",
        "  fig.savefig('pred.png')\n",
        "\n",
        "  # and plot how the cost varies as the gradient descent proceeds\n",
        "  fig2, ax2 = plt.subplots(figsize=(12, 8))\n",
        "  ax2.semilogy(cost,'r')\n",
        "  ax2.set_xlabel('iteration')\n",
        "  ax2.set_ylabel('cost')\n",
        "  fig2.savefig('cost.png')\n",
        "  \n",
        "  # plot the cost function\n",
        "  fig3 = plt.figure()\n",
        "  ax3 = fig3.add_subplot(1, 1, 1, projection='3d')\n",
        "  n=100\n",
        "  theta0, theta1 = np.meshgrid(np.linspace(-3, 3, n), np.linspace(-3, 2, n))\n",
        "  cost = np.empty((n,n))\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      cost[i,j] = computeCost(Xt,yt,(theta0[i,j],theta1[i,j]))\n",
        "  ax3.plot_surface(theta0,theta1,cost)\n",
        "  ax3.set_xlabel('theta0')\n",
        "  ax3.set_ylabel('theta1')\n",
        "  ax3.set_zlabel('J(theta)')\n",
        "  fig3.savefig('J.png')\n",
        "  \n",
        "# end def main()  \n",
        "  \n",
        "print (datetime.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNsoCBRt1bha",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiLpSKwE1ckc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (datetime.now())\n",
        "\n",
        "main()\n",
        "\n",
        "print (datetime.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpP7InSLDUl4",
        "colab_type": "text"
      },
      "source": [
        "##_ \n",
        "_testing section_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjI-DG_EDV76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test section (predict)\n",
        "# assume all defs are in place \n",
        "# but main hasn't run\n",
        "print(\"Test of multi variable prediction\")\n",
        "print(\"Three variables - five data points - with B0\")\n",
        "test_array = np.array([[1,2,3,5],\n",
        "                       [1,7,11,13],\n",
        "                       [1,17,19,23],\n",
        "                       [1,29,31,37],\n",
        "                       [1,41,43,47]])\n",
        "print (\"shape of test data : \" , test_array.shape )\n",
        "test_theta = np.array([1,2,3,5])\n",
        "print (\"shape of test theta : \", test_theta.shape )\n",
        "\n",
        "test_predict = predict (test_array, test_theta)\n",
        "print(test_predict)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfEqQxWOfZuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Test of multi variable cost\")\n",
        "print (\"cost when theta is all zeros and when theta is correct\")\n",
        "test_array = np.array([[1,2,3,5],\n",
        "                       [1,7,11,13],\n",
        "                       [1,17,19,23],\n",
        "                       [1,29,31,37],\n",
        "                       [1,41,43,47]])\n",
        "print (\"shape of test data : \" , test_array.shape )\n",
        "test_theta = np.array([0,0,0,0])\n",
        "print (\"shape of test theta : \", test_theta.shape )\n",
        "test_results = np.array([22,61,117,191,261])\n",
        "print (\"shape of test results : \", test_results.shape )\n",
        "good_theta = np.array([5,3,2,1])\n",
        "print (\"shape of correct theta : \", good_theta.shape )\n",
        "\n",
        "test_cost =  computeCost(test_array, test_results, test_theta)\n",
        "print (\"cost at theta all zeros : \" , test_cost)\n",
        "\n",
        "good_cost =  computeCost(test_array, test_results, good_theta)\n",
        "print (\"cost at correct theta : \" , good_cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMeRkQNxv3H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Test of Gradient Descent\")\n",
        "print (\"At zero theta and correct theta\")\n",
        "test_array = np.array([[1,2,3,5],\n",
        "                       [1,7,11,13],\n",
        "                       [1,17,19,23],\n",
        "                       [1,29,31,37],\n",
        "                       [1,41,43,47]])\n",
        "print (\"shape of test data : \" , test_array.shape )\n",
        "test_theta = np.array([0,0,0,0])\n",
        "print (\"shape of test theta : \", test_theta.shape )\n",
        "test_results = np.array([22,61,117,191,261])\n",
        "print (\"shape of test results : \", test_results.shape )\n",
        "good_theta = np.array([5,3,2,1])\n",
        "\n",
        "test_grad =  computeGradient(test_array, test_results, test_theta)\n",
        "print (\"gradient at theta all zeros : \" , test_grad)\n",
        "\n",
        "good_grad =  computeGradient(test_array, test_results, good_theta)\n",
        "print (\"gradient at theta correct : \" , good_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oS8R4vJ0xoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# full implementation with multi variable test data \n",
        "X = np.array([[2,3,5],\n",
        "              [7,11,13],\n",
        "              [17,19,23],\n",
        "              [29,31,37],\n",
        "              [41,43,47]])\n",
        "print (\"shape of test data : \" , X.shape )\n",
        "print (\"test data : \\n \", X)\n",
        "\n",
        "# perfectly linear results\n",
        "# y = np.array([22,61,117,191,261])\n",
        "\n",
        "# Or with some some non linearity \n",
        "y = np.array([23,60,118,193,260])\n",
        "\n",
        "print (\"shape of test results : \", y.shape )\n",
        "print (\"results : \" , y )\n",
        "\n",
        "good_theta = np.array([5,3,2,1])\n",
        "\n",
        "# Starting Position \n",
        "# note : without col of 1s in data (they get added below)\n",
        "\n",
        "\n",
        "# split the data into training and test parts\n",
        "#   note : current split is 100% train\n",
        "(Xtrain, ytrain, Xtest, ytest)=splitData(X,y)\n",
        "\n",
        "# add a column of ones to input data\n",
        "m=len(ytrain) # m is number of training data points\n",
        "# note this is a flaw in the original code as it was len(y) which only works if\n",
        "# the train/test split is 100% - so it needs to be len (ytrain) to avoid confusion\n",
        "Xtrain = np.column_stack((np.ones((m)), Xtrain))\n",
        "\n",
        "print (\"Shape of training data : \" , Xtrain.shape)\n",
        "print (\"Training Data : \\n \" , Xtrain)\n",
        " \n",
        "(m,n)=Xtrain.shape # m is number of data points, n number of features\n",
        "\n",
        "# rescale training data to lie between 0 and 1\n",
        "(Xt,Xscale) = normaliseData(Xtrain)\n",
        "(yt,yscale) = normaliseData(ytrain)\n",
        "\n",
        "print (\"Shape of training data : \" , Xt.shape)\n",
        "print (\"Training Data : \\n \" , Xt)\n",
        "\n",
        "# perform gradient descent to \"fit\" the model parameters\n",
        "# print('running gradient descent ...')\n",
        "# theta, cost = gradientDescent(Xt, yt, n)\n",
        "# print('after running gradientDescent() theta=',theta , \"\\n at cost : \" , cost)\n",
        "\n",
        "theta_init = np.zeros(n)\n",
        "iters = 1000000\n",
        "alpha = 0.1\n",
        "\n",
        "initial_cost = computeCost ( Xt, yt, theta_init)\n",
        "print (\"Initial theta : \" , theta_init )\n",
        "print (\"Initial cost = \", initial_cost)\n",
        "\n",
        "\n",
        "print('running gradient descent ...')\n",
        "theta_new, cost = gradDescent(Xt, yt, theta_init, iters, alpha)\n",
        "# print('after running gradientDescent() theta=',theta , \"\\n at cost : \" , cost)\n",
        "\n",
        "final_cost = cost[len(cost)-1]\n",
        "\n",
        "print (\"final theta : \" , theta_new )\n",
        "print (\"final cost = \", final_cost)\n",
        "\n",
        "\n",
        "# and plot how the cost varies as the gradient descent proceeds\n",
        "fig2, ax2 = plt.subplots(figsize=(12, 8))\n",
        "ax2.semilogy(cost,'r')\n",
        "ax2.set_xlabel('iteration')\n",
        "ax2.set_ylabel('cost')\n",
        "# fig2.savefig('cost.png')\n",
        "\n",
        "theta_init = theta_new\n",
        "iters = 5\n",
        "alpha = 0.1\n",
        "\n",
        "initial_cost = computeCost ( Xt, yt, theta_init)\n",
        "print (\"Initial theta : \" , theta_init )\n",
        "print (\"Initial cost = \", initial_cost)\n",
        "\n",
        "\n",
        "print('running gradient descent ...')\n",
        "theta_new, cost = gradDescent(Xt, yt, theta_init, iters, alpha)\n",
        "# print('after running gradientDescent() theta=',theta , \"\\n at cost : \" , cost)\n",
        "\n",
        "final_cost = cost[len(cost)-1]\n",
        "\n",
        "print (\"final theta : \" , theta_new )\n",
        "print (\"final cost = \", final_cost)\n",
        "\n",
        "\n",
        "# and plot how the cost varies as the gradient descent proceeds\n",
        "fig3, ax3 = plt.subplots(figsize=(20, 8))\n",
        "ax3.semilogy(cost,'r')\n",
        "ax3.set_xlabel('iteration')\n",
        "ax3.set_ylabel('cost')\n",
        "# fig2.savefig('cost.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNFAS80nGUHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (test_array, \"\\n\")\n",
        "print (test_array * 2, \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLVjtO73Gekf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (test_array + test_array, \"\\n\")\n",
        "print (test_array[0,:], \"\\n\")\n",
        "print (test_array[1,:], \"\\n\")\n",
        "print (test_array[2,:], \"\\n\")\n",
        "print (test_array[:,0], \"\\n\")\n",
        "print (test_array[:,1], \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOFsB7PkWMgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_1 = np.zeros((test_array.shape[0],test_array.shape[1]))\n",
        "print (predict_1.shape, \"\\n\")\n",
        "print (predict_1, \"\\n\")\n",
        "\n",
        "print (predict_1[0,:], \"\\n\")\n",
        "print (predict_1[1,:], \"\\n\")\n",
        "print (predict_1[2,:], \"\\n\")\n",
        "print (predict_1[:,0], \"\\n\")\n",
        "print (predict_1[:,1], \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7KElaA90mQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testnum = \"Case #1\"\n",
        "myX = np.array([1,1])\n",
        "mytheta = (1,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_2lfFOB9p-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testnum = \"Case #2\"\n",
        "myX = np.array([[1,1],[5,5]])\n",
        "mytheta = (1,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NEBjvfq-Z4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (testnum)\n",
        "print (datetime.now(), \"\\n\")\n",
        "print (\"Shape of myX : \", myX.shape, \"\\n\")\n",
        "print (\"Type of myX.shape : \" , type (myX.shape), \"\\n\")\n",
        "print (\"Len of myX.shape : \", len(myX.shape), \"\\n\")\n",
        "if len(myX.shape) == 1 : \n",
        "  print (\"myX col 0 : \", myX[0], \"\\n\")\n",
        "  print (\"myX col 1 : \", myX[1], \"\\n\")\n",
        "else : \n",
        "  print (\"myX col 0 : \", myX[:,0], \"\\n\")\n",
        "  print (\"myX col 1 : \", myX[:,1], \"\\n\")\n",
        "print (mytheta[0], \"\\n\")\n",
        "print (mytheta[1], \"\\n\", \"\\n\")\n",
        "mypredict_1 = predict(myX,mytheta)\n",
        "print (mypredict_1.shape, \"\\n\")\n",
        "print (mypredict_1, \"\\n\", \"\\n\")\n",
        "print (datetime.now(), \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoHThVczECeX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie7Prpo2EDFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multi dimensional test example\n",
        "# need two dependant variables \n",
        "# will produce a planar regression.\n",
        "# need some data\n",
        "# use the existing amazon and google data \n",
        "# but generate a new result variable\n",
        "# based on an integer multiple of each of the variables \n",
        "# with a randon factor thrown into each plus an additional \n",
        "# randon factor.\n",
        "data=np.loadtxt('https://raw.githubusercontent.com/johnsl01/linreg/master/stockprices.csv',usecols=(1,2))\n",
        "# X=data[:,0]\n",
        "# y=data[:,1]\n",
        "X = data\n",
        "y = X[:,0]*3 \n",
        "y = y + X[:,1]*2\n",
        "print (X.shape, y.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}